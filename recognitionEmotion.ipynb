{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7420888,"sourceType":"datasetVersion","datasetId":4317501}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Flatten, Dense, Input, LSTM, Dropout\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nimport seaborn as sns\nfrom scipy.signal import welch\nfrom scipy.stats import entropy, skew, kurtosis\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import LabelBinarizer","metadata":{"execution":{"iopub.status.busy":"2024-12-15T08:03:08.465814Z","iopub.execute_input":"2024-12-15T08:03:08.466552Z","iopub.status.idle":"2024-12-15T08:03:11.945127Z","shell.execute_reply.started":"2024-12-15T08:03:08.466508Z","shell.execute_reply":"2024-12-15T08:03:11.944375Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2024-12-15 08:03:08.831224: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-12-15 08:03:08.831285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-12-15 08:03:08.833276: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\ndef read_data(filename):\n    with open(filename, 'rb') as f:\n        data = pickle.load(f, encoding='latin1')\n    return data\n\nfiles = [f\"s{n:02d}\" for n in range(1, 33)]\n\nlabels, data = [], []\n\nfor file in files:\n    filepath = f\"/kaggle/input/deap-dataset/data_preprocessed_python/{file}.dat\"\n    d = read_data(filepath)\n    labels.append(d['labels'])\n    data.append(d['data'])\n\nlabels = np.array(labels)\ndata = np.array(data)\n\nprint(\"Labels shape: \", labels.shape)\nprint(\"Data shape: \", data.shape)\n\neeg_data = data[:, :, :32, -7680:]\nprint(\"EEG data shape: \", eeg_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-12-15T08:03:11.946387Z","iopub.execute_input":"2024-12-15T08:03:11.946804Z","iopub.status.idle":"2024-12-15T08:03:22.417909Z","shell.execute_reply.started":"2024-12-15T08:03:11.946780Z","shell.execute_reply":"2024-12-15T08:03:22.417061Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Labels shape:  (32, 40, 4)\nData shape:  (32, 40, 40, 8064)\nEEG data shape:  (32, 40, 32, 7680)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def extract_psd_feature(data):\n    psd_features = []\n    for channel_data in data:\n        f, psd = welch(channel_data, fs=128)\n        psd_features.append(psd)\n    return np.array(psd_features)\n\ndef extract_entropy_feature(data):\n    entropy_features = []\n    for channel_data in data:\n        prob_dist, _ = np.histogram(channel_data, bins=128, density=True)\n        prob_dist = prob_dist / np.sum(prob_dist)\n        entropy_features.append(entropy(prob_dist))\n    return np.array(entropy_features)\n\ndef extract_sd_feature(data):\n    return np.std(data, axis=1)\n\ndef extract_mean_feature(data):\n    return np.mean(data, axis=1)\ndef extract_variance_feature(data):\n    return np.var(data, axis=1)\n\ndef extract_skewness_feature(data):\n    return skew(data, axis=1)\n\ndef extract_kurtosis_feature(data):\n    return kurtosis(data, axis=1)\n\ndef preprocess_data(eeg_data, labels, feature_type):\n    data_features, data_labels, data_labels_valence = [], [], []\n    \n    for subject in range(eeg_data.shape[0]):\n        for trial in range(eeg_data.shape[1]):\n            trial_data = eeg_data[subject, trial, :, :]\n            if feature_type == 'psd':\n                features = extract_psd_feature(trial_data)\n            elif feature_type == 'entropy':\n                features = extract_entropy_feature(trial_data)\n            elif feature_type == 'sd':\n                features = extract_sd_feature(trial_data)\n            elif feature_type == 'mean':\n                features = extract_mean_feature(trial_data)\n            elif feature_type == 'variance':\n                features = extract_variance_feature(trial_data)\n            elif feature_type == 'skewness':\n                features = extract_skewness_feature(trial_data)\n            elif feature_type == 'kurtosis':\n                features = extract_kurtosis_feature(trial_data)\n            else:\n                raise ValueError(\"Unknown feature type\")\n            \n            data_features.append(features)\n            arousal_label = labels[subject, trial, 0]\n            data_labels.append(1 if arousal_label > 5 else 0)\n            valence_label = labels[subject, trial, 1]\n            data_labels_valence.append(1 if valence_label > 5 else 0)\n    \n    return np.array(data_features), np.array(data_labels), np.array(data_labels_valence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T08:03:22.419203Z","iopub.execute_input":"2024-12-15T08:03:22.419460Z","iopub.status.idle":"2024-12-15T08:03:22.429138Z","shell.execute_reply.started":"2024-12-15T08:03:22.419438Z","shell.execute_reply":"2024-12-15T08:03:22.428296Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"feature_types = ['psd', 'entropy', 'sd', 'mean', 'variance', 'skewness', 'kurtosis']\n\nall_features = {}\nfor feature_type in feature_types:\n    features, labels_processed, labels_processed_valence = preprocess_data(eeg_data, labels, feature_type)\n    all_features[feature_type] = (features, labels_processed, labels_processed_valence)\n    print(f\"{feature_type.capitalize()} Features shape: \", features.shape)\n    print(f\"{feature_type.capitalize()} Arousal Labels shape: \", labels_processed.shape)\n    print(f\"{feature_type.capitalize()} Valence Labels shape: \", labels_processed_valence.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T08:03:22.430174Z","iopub.execute_input":"2024-12-15T08:03:22.430421Z","iopub.status.idle":"2024-12-15T08:03:56.176183Z","shell.execute_reply.started":"2024-12-15T08:03:22.430401Z","shell.execute_reply":"2024-12-15T08:03:56.175318Z"}},"outputs":[{"name":"stdout","text":"Psd Features shape:  (1280, 32, 129)\nPsd Arousal Labels shape:  (1280,)\nPsd Valence Labels shape:  (1280,)\nEntropy Features shape:  (1280, 32)\nEntropy Arousal Labels shape:  (1280,)\nEntropy Valence Labels shape:  (1280,)\nSd Features shape:  (1280, 32)\nSd Arousal Labels shape:  (1280,)\nSd Valence Labels shape:  (1280,)\nMean Features shape:  (1280, 32)\nMean Arousal Labels shape:  (1280,)\nMean Valence Labels shape:  (1280,)\nVariance Features shape:  (1280, 32)\nVariance Arousal Labels shape:  (1280,)\nVariance Valence Labels shape:  (1280,)\nSkewness Features shape:  (1280, 32)\nSkewness Arousal Labels shape:  (1280,)\nSkewness Valence Labels shape:  (1280,)\nKurtosis Features shape:  (1280, 32)\nKurtosis Arousal Labels shape:  (1280,)\nKurtosis Valence Labels shape:  (1280,)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# CNN + LSTM\ndef create_cnn_lstm_model(input_shape):\n    # inputs = Input(shape=input_shape)\n    \n    # # 1st Conv Block\n    # x = Conv1D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n    # x = BatchNormalization()(x)\n    # x = MaxPooling1D(pool_size=2)(x)\n    \n    # # 2nd Conv Block\n    # x = Conv1D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n    # x = BatchNormalization()(x)\n    # x = MaxPooling1D(pool_size=2)(x)\n    \n    # # 3rd Conv Block \n    # x = Conv1D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n    # x = BatchNormalization()(x)\n    # x = MaxPooling1D(pool_size=2)(x)\n    \n    # # LSTM\n    # x = LSTM(256, return_sequences=False)(x)\n    \n    # x = Dense(units=512, activation='relu')(x)\n    # x = Dropout(0.5)(x)  \n    # x = Dense(units=256, activation='relu')(x)\n    \n    # outputs = Dense(units=1, activation='sigmoid')(x)\n    inputs = Input(shape=input_shape)\n\n    # LSTM Layer\n    x1 = LSTM(input_shape[0])(inputs)  # Số units của LSTM bằng số timestep (input_shape[0])\n    \n    # Dense Layer 1\n    x2 = Dense(input_shape[0])(x1)  # Dense layer không có activation\n    \n    # Dense Layer 2\n    x3 = Dense(12)(x2)  # Dense layer với 12 units, không có activation\n    \n    # Output Layer\n    outputs = Dense(1, activation='sigmoid')(x2)\n        \n    model = Model(inputs, outputs)\n    return model\n\nfeature_types = ['psd']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T08:25:06.580031Z","iopub.execute_input":"2024-12-15T08:25:06.581018Z","iopub.status.idle":"2024-12-15T08:25:06.587824Z","shell.execute_reply.started":"2024-12-15T08:25:06.580987Z","shell.execute_reply":"2024-12-15T08:25:06.586829Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"\nX_all = []\ny_all = []\n\nfor feature_type in feature_types:\n    features, arousal_labels, _ = all_features[feature_type]\n    \n    for channel in range(features.shape[2]):\n        channel_data = features[:, :, channel]  \n        X_all.append(channel_data)\n        y_all.append(arousal_labels)\n\nX_all = np.concatenate(X_all, axis=0)  \ny_all = np.concatenate(y_all, axis=0)  \n\nprint(\"Concatenated Features Shape: \", X_all.shape)\nprint(\"Concatenated Arousal Labels Shape: \", y_all.shape)\n\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T08:16:27.488200Z","iopub.execute_input":"2024-12-15T08:16:27.488561Z","iopub.status.idle":"2024-12-15T08:16:27.532665Z","shell.execute_reply.started":"2024-12-15T08:16:27.488530Z","shell.execute_reply":"2024-12-15T08:16:27.531535Z"}},"outputs":[{"name":"stdout","text":"Concatenated Features Shape:  (165120, 32)\nConcatenated Arousal Labels Shape:  (165120,)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import os\nimport wandb\n\n# Đọc API key từ biến môi trường\napi_key = os.environ.get(\"88aea2f639fada32b4501731dc07e972dc732128\")\nwandb.login(key=api_key)\nwandb.init(project=\"Recognition Emotion\", config={\n               \"learning_rate\": 0.001,\n               \"epochs\": 150,\n               \"batch_size\": 32,\n               \"feature_type\": \"psd\", # Sẽ được cập nhật sau\n               \"model\": \"CNN-LSTM\"\n           })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T08:31:08.323105Z","iopub.execute_input":"2024-12-15T08:31:08.323420Z","iopub.status.idle":"2024-12-15T08:31:29.453342Z","shell.execute_reply.started":"2024-12-15T08:31:08.323397Z","shell.execute_reply":"2024-12-15T08:31:29.452549Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:g639bo03) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c8005bfd4104969a12fb11d8d16160e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fold_1/epoch</td><td>▁</td></tr><tr><td>fold_1/f1_score</td><td>▁</td></tr><tr><td>fold_1/train_accuracy</td><td>▁</td></tr><tr><td>fold_1/train_loss</td><td>▁</td></tr><tr><td>fold_1/val_accuracy</td><td>▁</td></tr><tr><td>fold_1/val_loss</td><td>▁</td></tr><tr><td>fold_2/epoch</td><td>▁</td></tr><tr><td>fold_2/f1_score</td><td>▁</td></tr><tr><td>fold_2/train_accuracy</td><td>▁</td></tr><tr><td>fold_2/train_loss</td><td>▁</td></tr><tr><td>fold_2/val_accuracy</td><td>▁</td></tr><tr><td>fold_2/val_loss</td><td>▁</td></tr><tr><td>fold_3/epoch</td><td>▁</td></tr><tr><td>fold_3/f1_score</td><td>▁</td></tr><tr><td>fold_3/train_accuracy</td><td>▁</td></tr><tr><td>fold_3/train_loss</td><td>▁</td></tr><tr><td>fold_3/val_accuracy</td><td>▁</td></tr><tr><td>fold_3/val_loss</td><td>▁</td></tr><tr><td>fold_4/epoch</td><td>▁</td></tr><tr><td>fold_4/f1_score</td><td>▁</td></tr><tr><td>fold_4/train_accuracy</td><td>▁</td></tr><tr><td>fold_4/train_loss</td><td>▁</td></tr><tr><td>fold_4/val_accuracy</td><td>▁</td></tr><tr><td>fold_4/val_loss</td><td>▁</td></tr><tr><td>fold_5/epoch</td><td>▁</td></tr><tr><td>fold_5/f1_score</td><td>▁</td></tr><tr><td>fold_5/train_accuracy</td><td>▁</td></tr><tr><td>fold_5/train_loss</td><td>▁</td></tr><tr><td>fold_5/val_accuracy</td><td>▁</td></tr><tr><td>fold_5/val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fold_1/epoch</td><td>0</td></tr><tr><td>fold_1/f1_score</td><td>0.68643</td></tr><tr><td>fold_1/train_accuracy</td><td>0.56403</td></tr><tr><td>fold_1/train_loss</td><td>0.68231</td></tr><tr><td>fold_1/val_accuracy</td><td>0.57364</td></tr><tr><td>fold_1/val_loss</td><td>0.67579</td></tr><tr><td>fold_2/epoch</td><td>0</td></tr><tr><td>fold_2/f1_score</td><td>0.68231</td></tr><tr><td>fold_2/train_accuracy</td><td>0.56501</td></tr><tr><td>fold_2/train_loss</td><td>0.68152</td></tr><tr><td>fold_2/val_accuracy</td><td>0.57737</td></tr><tr><td>fold_2/val_loss</td><td>0.67291</td></tr><tr><td>fold_3/epoch</td><td>0</td></tr><tr><td>fold_3/f1_score</td><td>0.68871</td></tr><tr><td>fold_3/train_accuracy</td><td>0.56387</td></tr><tr><td>fold_3/train_loss</td><td>0.68228</td></tr><tr><td>fold_3/val_accuracy</td><td>0.57204</td></tr><tr><td>fold_3/val_loss</td><td>0.67582</td></tr><tr><td>fold_4/epoch</td><td>0</td></tr><tr><td>fold_4/f1_score</td><td>0.67929</td></tr><tr><td>fold_4/train_accuracy</td><td>0.56458</td></tr><tr><td>fold_4/train_loss</td><td>0.68208</td></tr><tr><td>fold_4/val_accuracy</td><td>0.57292</td></tr><tr><td>fold_4/val_loss</td><td>0.67876</td></tr><tr><td>fold_5/epoch</td><td>0</td></tr><tr><td>fold_5/f1_score</td><td>0.6888</td></tr><tr><td>fold_5/train_accuracy</td><td>0.55971</td></tr><tr><td>fold_5/train_loss</td><td>0.68369</td></tr><tr><td>fold_5/val_accuracy</td><td>0.57216</td></tr><tr><td>fold_5/val_loss</td><td>0.67698</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">avid-star-14</strong> at: <a href='https://wandb.ai/trangdo/Recognition%20Emotion/runs/g639bo03' target=\"_blank\">https://wandb.ai/trangdo/Recognition%20Emotion/runs/g639bo03</a><br/> View project at: <a href='https://wandb.ai/trangdo/Recognition%20Emotion' target=\"_blank\">https://wandb.ai/trangdo/Recognition%20Emotion</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241215_080358-g639bo03/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:g639bo03). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.19.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241215_083108-ahp825mj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/trangdo/Recognition%20Emotion/runs/ahp825mj' target=\"_blank\">gallant-terrain-15</a></strong> to <a href='https://wandb.ai/trangdo/Recognition%20Emotion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/trangdo/Recognition%20Emotion' target=\"_blank\">https://wandb.ai/trangdo/Recognition%20Emotion</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/trangdo/Recognition%20Emotion/runs/ahp825mj' target=\"_blank\">https://wandb.ai/trangdo/Recognition%20Emotion/runs/ahp825mj</a>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"config={\n               \"learning_rate\": 0.001,\n               \"epochs\": 150,\n               \"batch_size\": 32,\n               \"feature_type\": \"psd\", # Sẽ được cập nhật sau\n               \"model\": \"CNN-LSTM\"\n           }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"f1_scores = []\ndef train_and_evaluate(model, X_train, y_train, X_test, y_test, fold):\n    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n    if fold == 0 : \n        model.summary()\n    history = model.fit(X_train, y_train, epochs=config[\"epochs\"], batch_size=32, validation_data=(X_test, y_test), verbose=1)\n    # config[\"epochs\"]\n    for epoch in range(config[\"epochs\"]):\n        wandb.log({\n            f\"fold_{fold+1}/epoch\": epoch,\n            f\"fold_{fold+1}/train_loss\": history.history['loss'][epoch],\n            f\"fold_{fold+1}/train_accuracy\": history.history['accuracy'][epoch],\n            f\"fold_{fold+1}/val_loss\": history.history['val_loss'][epoch],\n            f\"fold_{fold+1}/val_accuracy\": history.history['val_accuracy'][epoch]\n        })\n    y_pred = model.predict(X_test)\n    print(\"y_ pred : \", y_pred, \"  -------  y_test : \", y_test)\n    y_pred = (y_pred > 0.5).astype(int)\n    print(\"y_pred astype : \", y_pred)\n    \n    num_zeros = np.count_nonzero(y_pred == 0)\n    num_ones = np.count_nonzero(y_pred == 1)\n\n    # In ra kết quả\n    print(f\"Fold {fold + 1}:\")\n    print(f\"  Số lượng dự đoán là 0: {num_zeros}\")\n    print(f\"  Số lượng dự đoán là 1: {num_ones}\")\n\n    num_zeros_test = np.count_nonzero(y_test == 0)\n    num_ones_test = np.count_nonzero(y_test == 1)\n    \n    print(f\" test Số lượng dự đoán là 0: {num_zeros_test}\")\n    print(f\" test Số lượng dự đoán là 1: {num_ones_test}\")\n    \n    f1 = f1_score(y_test, y_pred)\n    \n    test_score = model.evaluate(X_test, y_test)\n\n    wandb.log({f\"fold_{fold+1}/f1_score\": f1})\n    f1_scores.append(f1)\n    \n    return test_score, f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T08:31:30.756802Z","iopub.execute_input":"2024-12-15T08:31:30.757146Z","iopub.status.idle":"2024-12-15T08:31:30.766107Z","shell.execute_reply.started":"2024-12-15T08:31:30.757116Z","shell.execute_reply":"2024-12-15T08:31:30.765220Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# from wandb.keras import WandbCallback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T08:31:32.160561Z","iopub.execute_input":"2024-12-15T08:31:32.161477Z","iopub.status.idle":"2024-12-15T08:31:32.165602Z","shell.execute_reply.started":"2024-12-15T08:31:32.161432Z","shell.execute_reply":"2024-12-15T08:31:32.164655Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for fold, (train_idx, val_idx) in enumerate(kf.split(X_all)):\n    print(f\"Training fold {fold + 1}\")\n    \n    X_train, X_val = X_all[train_idx], X_all[val_idx]\n    y_train, y_val = y_all[train_idx], y_all[val_idx]\n    \n    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n    \n    # CNN + LSTM\n    input_shape = (X_train.shape[1], 1)\n    model = create_cnn_lstm_model(input_shape)\n    \n    test_score, f1 = train_and_evaluate(model, X_train, y_train, X_val, y_val, fold)\n    \n    print(f\"Fold {fold + 1} Test Score: \", test_score)\n    print(f\"Fold {fold + 1} F1 Score: \", f1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T08:31:33.092307Z","iopub.execute_input":"2024-12-15T08:31:33.092891Z"}},"outputs":[{"name":"stdout","text":"Training fold 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_17\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,352\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,441\u001b[0m (21.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,441</span> (21.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,441\u001b[0m (21.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,441</span> (21.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.5524 - loss: 0.2468 - val_accuracy: 0.5777 - val_loss: 0.2414\nEpoch 2/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.5800 - loss: 0.2407 - val_accuracy: 0.5863 - val_loss: 0.2376\nEpoch 3/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.5885 - loss: 0.2366 - val_accuracy: 0.5951 - val_loss: 0.2343\nEpoch 4/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6012 - loss: 0.2332 - val_accuracy: 0.5941 - val_loss: 0.2343\nEpoch 5/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6053 - loss: 0.2314 - val_accuracy: 0.6007 - val_loss: 0.2308\nEpoch 6/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6087 - loss: 0.2295 - val_accuracy: 0.6003 - val_loss: 0.2314\nEpoch 7/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6141 - loss: 0.2274 - val_accuracy: 0.6093 - val_loss: 0.2285\nEpoch 8/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6131 - loss: 0.2267 - val_accuracy: 0.6090 - val_loss: 0.2279\nEpoch 9/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6184 - loss: 0.2247 - val_accuracy: 0.6104 - val_loss: 0.2274\nEpoch 10/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6219 - loss: 0.2237 - val_accuracy: 0.6164 - val_loss: 0.2252\nEpoch 11/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6243 - loss: 0.2221 - val_accuracy: 0.6175 - val_loss: 0.2241\nEpoch 12/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6269 - loss: 0.2215 - val_accuracy: 0.6227 - val_loss: 0.2223\nEpoch 13/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6297 - loss: 0.2193 - val_accuracy: 0.6219 - val_loss: 0.2217\nEpoch 14/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6311 - loss: 0.2189 - val_accuracy: 0.6202 - val_loss: 0.2234\nEpoch 15/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6328 - loss: 0.2184 - val_accuracy: 0.6251 - val_loss: 0.2211\nEpoch 16/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: 0.2172 - val_accuracy: 0.6270 - val_loss: 0.2204\nEpoch 17/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6400 - loss: 0.2158 - val_accuracy: 0.6270 - val_loss: 0.2196\nEpoch 18/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6399 - loss: 0.2152 - val_accuracy: 0.6259 - val_loss: 0.2203\nEpoch 19/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6398 - loss: 0.2154 - val_accuracy: 0.6315 - val_loss: 0.2179\nEpoch 20/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6431 - loss: 0.2136 - val_accuracy: 0.6324 - val_loss: 0.2182\nEpoch 21/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6405 - loss: 0.2138 - val_accuracy: 0.6318 - val_loss: 0.2179\nEpoch 22/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6465 - loss: 0.2118 - val_accuracy: 0.6335 - val_loss: 0.2167\nEpoch 23/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6450 - loss: 0.2118 - val_accuracy: 0.6326 - val_loss: 0.2164\nEpoch 24/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6445 - loss: 0.2121 - val_accuracy: 0.6350 - val_loss: 0.2155\nEpoch 25/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6471 - loss: 0.2109 - val_accuracy: 0.6293 - val_loss: 0.2184\nEpoch 26/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6470 - loss: 0.2109 - val_accuracy: 0.6316 - val_loss: 0.2177\nEpoch 27/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6521 - loss: 0.2092 - val_accuracy: 0.6324 - val_loss: 0.2164\nEpoch 28/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6518 - loss: 0.2086 - val_accuracy: 0.6361 - val_loss: 0.2147\nEpoch 29/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6527 - loss: 0.2085 - val_accuracy: 0.6372 - val_loss: 0.2146\nEpoch 30/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6532 - loss: 0.2081 - val_accuracy: 0.6381 - val_loss: 0.2145\nEpoch 31/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6524 - loss: 0.2084 - val_accuracy: 0.6379 - val_loss: 0.2148\nEpoch 32/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6556 - loss: 0.2068 - val_accuracy: 0.6377 - val_loss: 0.2142\nEpoch 33/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6514 - loss: 0.2084 - val_accuracy: 0.6362 - val_loss: 0.2160\nEpoch 34/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6565 - loss: 0.2066 - val_accuracy: 0.6412 - val_loss: 0.2133\nEpoch 35/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6564 - loss: 0.2064 - val_accuracy: 0.6384 - val_loss: 0.2143\nEpoch 36/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6588 - loss: 0.2054 - val_accuracy: 0.6401 - val_loss: 0.2124\nEpoch 37/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6571 - loss: 0.2058 - val_accuracy: 0.6415 - val_loss: 0.2118\nEpoch 38/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6596 - loss: 0.2044 - val_accuracy: 0.6419 - val_loss: 0.2134\nEpoch 39/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6580 - loss: 0.2055 - val_accuracy: 0.6423 - val_loss: 0.2134\nEpoch 40/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6594 - loss: 0.2044 - val_accuracy: 0.6423 - val_loss: 0.2121\nEpoch 41/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6620 - loss: 0.2035 - val_accuracy: 0.6406 - val_loss: 0.2124\nEpoch 42/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6597 - loss: 0.2040 - val_accuracy: 0.6410 - val_loss: 0.2116\nEpoch 43/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6603 - loss: 0.2039 - val_accuracy: 0.6415 - val_loss: 0.2124\nEpoch 44/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6610 - loss: 0.2038 - val_accuracy: 0.6431 - val_loss: 0.2115\nEpoch 45/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6622 - loss: 0.2032 - val_accuracy: 0.6411 - val_loss: 0.2133\nEpoch 46/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6626 - loss: 0.2029 - val_accuracy: 0.6430 - val_loss: 0.2124\nEpoch 47/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6632 - loss: 0.2029 - val_accuracy: 0.6408 - val_loss: 0.2120\nEpoch 48/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6637 - loss: 0.2027 - val_accuracy: 0.6428 - val_loss: 0.2108\nEpoch 49/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6650 - loss: 0.2022 - val_accuracy: 0.6426 - val_loss: 0.2112\nEpoch 50/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6661 - loss: 0.2018 - val_accuracy: 0.6430 - val_loss: 0.2111\nEpoch 51/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6657 - loss: 0.2009 - val_accuracy: 0.6430 - val_loss: 0.2126\nEpoch 52/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6651 - loss: 0.2016 - val_accuracy: 0.6422 - val_loss: 0.2123\nEpoch 53/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6650 - loss: 0.2017 - val_accuracy: 0.6452 - val_loss: 0.2115\nEpoch 54/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6654 - loss: 0.2012 - val_accuracy: 0.6434 - val_loss: 0.2119\nEpoch 55/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6669 - loss: 0.2007 - val_accuracy: 0.6420 - val_loss: 0.2124\nEpoch 56/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6668 - loss: 0.2013 - val_accuracy: 0.6438 - val_loss: 0.2127\nEpoch 57/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6667 - loss: 0.2008 - val_accuracy: 0.6431 - val_loss: 0.2117\nEpoch 58/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6647 - loss: 0.2010 - val_accuracy: 0.6438 - val_loss: 0.2118\nEpoch 59/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6678 - loss: 0.2004 - val_accuracy: 0.6415 - val_loss: 0.2120\nEpoch 60/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6670 - loss: 0.2010 - val_accuracy: 0.6438 - val_loss: 0.2113\nEpoch 61/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6680 - loss: 0.1999 - val_accuracy: 0.6441 - val_loss: 0.2101\nEpoch 62/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6674 - loss: 0.1999 - val_accuracy: 0.6450 - val_loss: 0.2114\nEpoch 63/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6691 - loss: 0.1998 - val_accuracy: 0.6450 - val_loss: 0.2106\nEpoch 64/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6698 - loss: 0.1996 - val_accuracy: 0.6473 - val_loss: 0.2097\nEpoch 65/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6705 - loss: 0.1996 - val_accuracy: 0.6455 - val_loss: 0.2105\nEpoch 66/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6702 - loss: 0.1991 - val_accuracy: 0.6451 - val_loss: 0.2099\nEpoch 67/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6703 - loss: 0.1995 - val_accuracy: 0.6467 - val_loss: 0.2097\nEpoch 68/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6693 - loss: 0.1994 - val_accuracy: 0.6456 - val_loss: 0.2101\nEpoch 69/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6688 - loss: 0.1995 - val_accuracy: 0.6473 - val_loss: 0.2090\nEpoch 70/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6716 - loss: 0.1984 - val_accuracy: 0.6458 - val_loss: 0.2099\nEpoch 71/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6726 - loss: 0.1986 - val_accuracy: 0.6439 - val_loss: 0.2111\nEpoch 72/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6730 - loss: 0.1988 - val_accuracy: 0.6457 - val_loss: 0.2105\nEpoch 73/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6705 - loss: 0.1985 - val_accuracy: 0.6433 - val_loss: 0.2110\nEpoch 74/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6736 - loss: 0.1977 - val_accuracy: 0.6447 - val_loss: 0.2102\nEpoch 75/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6711 - loss: 0.1980 - val_accuracy: 0.6436 - val_loss: 0.2115\nEpoch 76/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6709 - loss: 0.1986 - val_accuracy: 0.6451 - val_loss: 0.2099\nEpoch 77/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6698 - loss: 0.1985 - val_accuracy: 0.6455 - val_loss: 0.2106\nEpoch 78/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6706 - loss: 0.1988 - val_accuracy: 0.6455 - val_loss: 0.2104\nEpoch 79/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6725 - loss: 0.1981 - val_accuracy: 0.6452 - val_loss: 0.2091\nEpoch 80/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6729 - loss: 0.1978 - val_accuracy: 0.6450 - val_loss: 0.2100\nEpoch 81/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6714 - loss: 0.1976 - val_accuracy: 0.6442 - val_loss: 0.2107\nEpoch 82/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6714 - loss: 0.1981 - val_accuracy: 0.6457 - val_loss: 0.2094\nEpoch 83/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6735 - loss: 0.1974 - val_accuracy: 0.6458 - val_loss: 0.2108\nEpoch 84/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6737 - loss: 0.1972 - val_accuracy: 0.6450 - val_loss: 0.2104\nEpoch 85/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6725 - loss: 0.1978 - val_accuracy: 0.6488 - val_loss: 0.2094\nEpoch 86/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6739 - loss: 0.1974 - val_accuracy: 0.6463 - val_loss: 0.2096\nEpoch 87/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6717 - loss: 0.1975 - val_accuracy: 0.6464 - val_loss: 0.2097\nEpoch 88/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6736 - loss: 0.1971 - val_accuracy: 0.6459 - val_loss: 0.2097\nEpoch 89/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6752 - loss: 0.1966 - val_accuracy: 0.6451 - val_loss: 0.2102\nEpoch 90/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6742 - loss: 0.1968 - val_accuracy: 0.6467 - val_loss: 0.2103\nEpoch 91/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6746 - loss: 0.1965 - val_accuracy: 0.6456 - val_loss: 0.2111\nEpoch 92/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6750 - loss: 0.1966 - val_accuracy: 0.6473 - val_loss: 0.2097\nEpoch 93/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6720 - loss: 0.1973 - val_accuracy: 0.6443 - val_loss: 0.2121\nEpoch 94/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6759 - loss: 0.1961 - val_accuracy: 0.6471 - val_loss: 0.2101\nEpoch 95/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6783 - loss: 0.1956 - val_accuracy: 0.6474 - val_loss: 0.2098\nEpoch 96/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6766 - loss: 0.1960 - val_accuracy: 0.6471 - val_loss: 0.2096\nEpoch 97/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6746 - loss: 0.1965 - val_accuracy: 0.6465 - val_loss: 0.2096\nEpoch 98/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6766 - loss: 0.1955 - val_accuracy: 0.6456 - val_loss: 0.2101\nEpoch 99/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6744 - loss: 0.1962 - val_accuracy: 0.6496 - val_loss: 0.2092\nEpoch 100/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6751 - loss: 0.1961 - val_accuracy: 0.6452 - val_loss: 0.2098\nEpoch 101/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6759 - loss: 0.1958 - val_accuracy: 0.6432 - val_loss: 0.2106\nEpoch 102/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6733 - loss: 0.1969 - val_accuracy: 0.6480 - val_loss: 0.2089\nEpoch 103/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6747 - loss: 0.1962 - val_accuracy: 0.6463 - val_loss: 0.2103\nEpoch 104/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6750 - loss: 0.1958 - val_accuracy: 0.6451 - val_loss: 0.2105\nEpoch 105/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6751 - loss: 0.1954 - val_accuracy: 0.6477 - val_loss: 0.2098\nEpoch 106/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.1950 - val_accuracy: 0.6503 - val_loss: 0.2090\nEpoch 107/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6783 - loss: 0.1953 - val_accuracy: 0.6496 - val_loss: 0.2101\nEpoch 108/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6754 - loss: 0.1953 - val_accuracy: 0.6479 - val_loss: 0.2102\nEpoch 109/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6762 - loss: 0.1952 - val_accuracy: 0.6476 - val_loss: 0.2092\nEpoch 110/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6746 - loss: 0.1958 - val_accuracy: 0.6480 - val_loss: 0.2097\nEpoch 111/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6759 - loss: 0.1957 - val_accuracy: 0.6434 - val_loss: 0.2106\nEpoch 112/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6764 - loss: 0.1948 - val_accuracy: 0.6463 - val_loss: 0.2101\nEpoch 113/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6777 - loss: 0.1948 - val_accuracy: 0.6463 - val_loss: 0.2106\nEpoch 114/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6745 - loss: 0.1952 - val_accuracy: 0.6457 - val_loss: 0.2093\nEpoch 115/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6749 - loss: 0.1959 - val_accuracy: 0.6476 - val_loss: 0.2103\nEpoch 116/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6770 - loss: 0.1954 - val_accuracy: 0.6471 - val_loss: 0.2093\nEpoch 117/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6760 - loss: 0.1954 - val_accuracy: 0.6455 - val_loss: 0.2115\nEpoch 118/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6781 - loss: 0.1950 - val_accuracy: 0.6461 - val_loss: 0.2101\nEpoch 119/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6771 - loss: 0.1947 - val_accuracy: 0.6450 - val_loss: 0.2110\nEpoch 120/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6789 - loss: 0.1944 - val_accuracy: 0.6477 - val_loss: 0.2093\nEpoch 121/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6760 - loss: 0.1950 - val_accuracy: 0.6499 - val_loss: 0.2089\nEpoch 122/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 0.1943 - val_accuracy: 0.6490 - val_loss: 0.2094\nEpoch 123/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6801 - loss: 0.1944 - val_accuracy: 0.6496 - val_loss: 0.2090\nEpoch 124/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6779 - loss: 0.1941 - val_accuracy: 0.6480 - val_loss: 0.2094\nEpoch 125/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6807 - loss: 0.1935 - val_accuracy: 0.6474 - val_loss: 0.2091\nEpoch 126/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6789 - loss: 0.1947 - val_accuracy: 0.6474 - val_loss: 0.2097\nEpoch 127/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6782 - loss: 0.1952 - val_accuracy: 0.6491 - val_loss: 0.2078\nEpoch 128/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6798 - loss: 0.1938 - val_accuracy: 0.6472 - val_loss: 0.2092\nEpoch 129/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6795 - loss: 0.1938 - val_accuracy: 0.6491 - val_loss: 0.2103\nEpoch 130/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6813 - loss: 0.1933 - val_accuracy: 0.6474 - val_loss: 0.2097\nEpoch 131/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.1941 - val_accuracy: 0.6477 - val_loss: 0.2090\nEpoch 132/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6782 - loss: 0.1944 - val_accuracy: 0.6488 - val_loss: 0.2098\nEpoch 133/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6797 - loss: 0.1939 - val_accuracy: 0.6490 - val_loss: 0.2093\nEpoch 134/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6781 - loss: 0.1940 - val_accuracy: 0.6466 - val_loss: 0.2097\nEpoch 135/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6804 - loss: 0.1931 - val_accuracy: 0.6463 - val_loss: 0.2105\nEpoch 136/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.1942 - val_accuracy: 0.6505 - val_loss: 0.2093\nEpoch 137/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6779 - loss: 0.1937 - val_accuracy: 0.6506 - val_loss: 0.2096\nEpoch 138/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6802 - loss: 0.1934 - val_accuracy: 0.6522 - val_loss: 0.2070\nEpoch 139/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.1934 - val_accuracy: 0.6491 - val_loss: 0.2083\nEpoch 140/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6823 - loss: 0.1925 - val_accuracy: 0.6480 - val_loss: 0.2100\nEpoch 141/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 0.1944 - val_accuracy: 0.6507 - val_loss: 0.2089\nEpoch 142/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6823 - loss: 0.1929 - val_accuracy: 0.6488 - val_loss: 0.2093\nEpoch 143/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6826 - loss: 0.1926 - val_accuracy: 0.6505 - val_loss: 0.2085\nEpoch 144/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6794 - loss: 0.1932 - val_accuracy: 0.6466 - val_loss: 0.2108\nEpoch 145/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6786 - loss: 0.1936 - val_accuracy: 0.6480 - val_loss: 0.2103\nEpoch 146/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6808 - loss: 0.1936 - val_accuracy: 0.6508 - val_loss: 0.2083\nEpoch 147/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6797 - loss: 0.1930 - val_accuracy: 0.6469 - val_loss: 0.2108\nEpoch 148/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.1936 - val_accuracy: 0.6481 - val_loss: 0.2092\nEpoch 149/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6800 - loss: 0.1927 - val_accuracy: 0.6470 - val_loss: 0.2100\nEpoch 150/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6811 - loss: 0.1930 - val_accuracy: 0.6486 - val_loss: 0.2096\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\ny_ pred :  [[0.5442418 ]\n [0.54112035]\n [0.54264176]\n ...\n [0.5446212 ]\n [0.5446212 ]\n [0.5446212 ]]   -------  y_test :  [1 0 1 ... 0 0 1]\ny_pred astype :  [[1]\n [1]\n [1]\n ...\n [1]\n [1]\n [1]]\nFold 1:\n  Số lượng dự đoán là 0: 9064\n  Số lượng dự đoán là 1: 23960\n test Số lượng dự đoán là 0: 14778\n test Số lượng dự đoán là 1: 18246\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6293 - loss: 0.2218\nFold 1 Test Score:  [0.20963764190673828, 0.6485586166381836]\nFold 1 F1 Score:  0.7250154006539355\nTraining fold 2\nEpoch 1/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.5565 - loss: 0.2466 - val_accuracy: 0.5664 - val_loss: 0.2433\nEpoch 2/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.5738 - loss: 0.2417 - val_accuracy: 0.5763 - val_loss: 0.2397\nEpoch 3/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.5879 - loss: 0.2379 - val_accuracy: 0.5903 - val_loss: 0.2371\nEpoch 4/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.5992 - loss: 0.2340 - val_accuracy: 0.6049 - val_loss: 0.2321\nEpoch 5/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6028 - loss: 0.2321 - val_accuracy: 0.6040 - val_loss: 0.2311\nEpoch 6/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6077 - loss: 0.2297 - val_accuracy: 0.6092 - val_loss: 0.2293\nEpoch 7/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6125 - loss: 0.2282 - val_accuracy: 0.6116 - val_loss: 0.2273\nEpoch 8/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6132 - loss: 0.2270 - val_accuracy: 0.6144 - val_loss: 0.2267\nEpoch 9/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6175 - loss: 0.2252 - val_accuracy: 0.6149 - val_loss: 0.2256\nEpoch 10/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6187 - loss: 0.2235 - val_accuracy: 0.6196 - val_loss: 0.2246\nEpoch 11/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6215 - loss: 0.2232 - val_accuracy: 0.6222 - val_loss: 0.2230\nEpoch 12/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6277 - loss: 0.2206 - val_accuracy: 0.6226 - val_loss: 0.2223\nEpoch 13/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6287 - loss: 0.2205 - val_accuracy: 0.6260 - val_loss: 0.2212\nEpoch 14/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6316 - loss: 0.2188 - val_accuracy: 0.6253 - val_loss: 0.2214\nEpoch 15/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6323 - loss: 0.2186 - val_accuracy: 0.6282 - val_loss: 0.2197\nEpoch 16/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6373 - loss: 0.2174 - val_accuracy: 0.6288 - val_loss: 0.2188\nEpoch 17/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6328 - loss: 0.2175 - val_accuracy: 0.6327 - val_loss: 0.2174\nEpoch 18/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6375 - loss: 0.2162 - val_accuracy: 0.6321 - val_loss: 0.2185\nEpoch 19/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6386 - loss: 0.2157 - val_accuracy: 0.6318 - val_loss: 0.2178\nEpoch 20/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6388 - loss: 0.2150 - val_accuracy: 0.6295 - val_loss: 0.2181\nEpoch 21/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6422 - loss: 0.2141 - val_accuracy: 0.6359 - val_loss: 0.2157\nEpoch 22/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6427 - loss: 0.2133 - val_accuracy: 0.6373 - val_loss: 0.2154\nEpoch 23/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6404 - loss: 0.2134 - val_accuracy: 0.6317 - val_loss: 0.2176\nEpoch 24/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6439 - loss: 0.2119 - val_accuracy: 0.6362 - val_loss: 0.2156\nEpoch 25/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6462 - loss: 0.2120 - val_accuracy: 0.6375 - val_loss: 0.2143\nEpoch 26/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6444 - loss: 0.2116 - val_accuracy: 0.6393 - val_loss: 0.2142\nEpoch 27/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6444 - loss: 0.2114 - val_accuracy: 0.6403 - val_loss: 0.2132\nEpoch 28/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6450 - loss: 0.2113 - val_accuracy: 0.6367 - val_loss: 0.2146\nEpoch 29/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6462 - loss: 0.2105 - val_accuracy: 0.6407 - val_loss: 0.2129\nEpoch 30/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6482 - loss: 0.2098 - val_accuracy: 0.6422 - val_loss: 0.2129\nEpoch 31/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6476 - loss: 0.2090 - val_accuracy: 0.6423 - val_loss: 0.2126\nEpoch 32/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6473 - loss: 0.2097 - val_accuracy: 0.6415 - val_loss: 0.2126\nEpoch 33/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6528 - loss: 0.2085 - val_accuracy: 0.6414 - val_loss: 0.2128\nEpoch 34/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6497 - loss: 0.2088 - val_accuracy: 0.6430 - val_loss: 0.2115\nEpoch 35/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6504 - loss: 0.2084 - val_accuracy: 0.6434 - val_loss: 0.2119\nEpoch 36/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6531 - loss: 0.2075 - val_accuracy: 0.6410 - val_loss: 0.2124\nEpoch 37/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6532 - loss: 0.2073 - val_accuracy: 0.6417 - val_loss: 0.2126\nEpoch 38/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6543 - loss: 0.2066 - val_accuracy: 0.6434 - val_loss: 0.2113\nEpoch 39/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6548 - loss: 0.2071 - val_accuracy: 0.6456 - val_loss: 0.2109\nEpoch 40/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6534 - loss: 0.2071 - val_accuracy: 0.6453 - val_loss: 0.2105\nEpoch 41/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6518 - loss: 0.2067 - val_accuracy: 0.6429 - val_loss: 0.2119\nEpoch 42/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6569 - loss: 0.2059 - val_accuracy: 0.6456 - val_loss: 0.2105\nEpoch 43/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6564 - loss: 0.2054 - val_accuracy: 0.6461 - val_loss: 0.2109\nEpoch 44/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6575 - loss: 0.2051 - val_accuracy: 0.6445 - val_loss: 0.2108\nEpoch 45/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 0.2054 - val_accuracy: 0.6437 - val_loss: 0.2125\nEpoch 46/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6567 - loss: 0.2054 - val_accuracy: 0.6457 - val_loss: 0.2112\nEpoch 47/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6569 - loss: 0.2045 - val_accuracy: 0.6497 - val_loss: 0.2098\nEpoch 48/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6595 - loss: 0.2041 - val_accuracy: 0.6465 - val_loss: 0.2101\nEpoch 49/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6621 - loss: 0.2036 - val_accuracy: 0.6457 - val_loss: 0.2097\nEpoch 50/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6606 - loss: 0.2036 - val_accuracy: 0.6477 - val_loss: 0.2099\nEpoch 51/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6594 - loss: 0.2032 - val_accuracy: 0.6471 - val_loss: 0.2098\nEpoch 52/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6622 - loss: 0.2030 - val_accuracy: 0.6437 - val_loss: 0.2110\nEpoch 53/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6652 - loss: 0.2026 - val_accuracy: 0.6470 - val_loss: 0.2104\nEpoch 54/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6630 - loss: 0.2026 - val_accuracy: 0.6466 - val_loss: 0.2101\nEpoch 55/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6624 - loss: 0.2034 - val_accuracy: 0.6465 - val_loss: 0.2108\nEpoch 56/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6634 - loss: 0.2027 - val_accuracy: 0.6480 - val_loss: 0.2093\nEpoch 57/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6635 - loss: 0.2023 - val_accuracy: 0.6468 - val_loss: 0.2095\nEpoch 58/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6620 - loss: 0.2022 - val_accuracy: 0.6460 - val_loss: 0.2104\nEpoch 59/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6631 - loss: 0.2020 - val_accuracy: 0.6479 - val_loss: 0.2089\nEpoch 60/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6638 - loss: 0.2019 - val_accuracy: 0.6509 - val_loss: 0.2096\nEpoch 61/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6653 - loss: 0.2017 - val_accuracy: 0.6476 - val_loss: 0.2106\nEpoch 62/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6659 - loss: 0.2007 - val_accuracy: 0.6521 - val_loss: 0.2083\nEpoch 63/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6639 - loss: 0.2015 - val_accuracy: 0.6479 - val_loss: 0.2095\nEpoch 64/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6664 - loss: 0.2012 - val_accuracy: 0.6485 - val_loss: 0.2092\nEpoch 65/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6646 - loss: 0.2012 - val_accuracy: 0.6480 - val_loss: 0.2097\nEpoch 66/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6660 - loss: 0.2006 - val_accuracy: 0.6473 - val_loss: 0.2089\nEpoch 67/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6643 - loss: 0.2010 - val_accuracy: 0.6493 - val_loss: 0.2093\nEpoch 68/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6673 - loss: 0.2004 - val_accuracy: 0.6495 - val_loss: 0.2084\nEpoch 69/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6672 - loss: 0.2000 - val_accuracy: 0.6486 - val_loss: 0.2086\nEpoch 70/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6655 - loss: 0.2009 - val_accuracy: 0.6486 - val_loss: 0.2105\nEpoch 71/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6682 - loss: 0.2000 - val_accuracy: 0.6493 - val_loss: 0.2087\nEpoch 72/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6690 - loss: 0.1995 - val_accuracy: 0.6525 - val_loss: 0.2079\nEpoch 73/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6702 - loss: 0.1993 - val_accuracy: 0.6469 - val_loss: 0.2102\nEpoch 74/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6662 - loss: 0.1999 - val_accuracy: 0.6447 - val_loss: 0.2114\nEpoch 75/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6669 - loss: 0.2003 - val_accuracy: 0.6502 - val_loss: 0.2087\nEpoch 76/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6725 - loss: 0.1989 - val_accuracy: 0.6475 - val_loss: 0.2101\nEpoch 77/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6703 - loss: 0.1993 - val_accuracy: 0.6505 - val_loss: 0.2083\nEpoch 78/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6714 - loss: 0.1979 - val_accuracy: 0.6513 - val_loss: 0.2084\nEpoch 79/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6690 - loss: 0.1988 - val_accuracy: 0.6505 - val_loss: 0.2092\nEpoch 80/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6710 - loss: 0.1985 - val_accuracy: 0.6519 - val_loss: 0.2085\nEpoch 81/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6700 - loss: 0.1982 - val_accuracy: 0.6505 - val_loss: 0.2087\nEpoch 82/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6706 - loss: 0.1987 - val_accuracy: 0.6503 - val_loss: 0.2085\nEpoch 83/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6703 - loss: 0.1985 - val_accuracy: 0.6515 - val_loss: 0.2086\nEpoch 84/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6704 - loss: 0.1980 - val_accuracy: 0.6511 - val_loss: 0.2083\nEpoch 85/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6717 - loss: 0.1978 - val_accuracy: 0.6520 - val_loss: 0.2081\nEpoch 86/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6719 - loss: 0.1982 - val_accuracy: 0.6534 - val_loss: 0.2072\nEpoch 87/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6747 - loss: 0.1968 - val_accuracy: 0.6501 - val_loss: 0.2079\nEpoch 88/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6747 - loss: 0.1973 - val_accuracy: 0.6487 - val_loss: 0.2100\nEpoch 89/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6715 - loss: 0.1978 - val_accuracy: 0.6507 - val_loss: 0.2077\nEpoch 90/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6726 - loss: 0.1975 - val_accuracy: 0.6533 - val_loss: 0.2079\nEpoch 91/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6737 - loss: 0.1965 - val_accuracy: 0.6508 - val_loss: 0.2081\nEpoch 92/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6721 - loss: 0.1977 - val_accuracy: 0.6507 - val_loss: 0.2095\nEpoch 93/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6733 - loss: 0.1967 - val_accuracy: 0.6540 - val_loss: 0.2074\nEpoch 94/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6736 - loss: 0.1966 - val_accuracy: 0.6516 - val_loss: 0.2088\nEpoch 95/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6754 - loss: 0.1967 - val_accuracy: 0.6516 - val_loss: 0.2084\nEpoch 96/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6716 - loss: 0.1980 - val_accuracy: 0.6503 - val_loss: 0.2086\nEpoch 97/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6743 - loss: 0.1974 - val_accuracy: 0.6502 - val_loss: 0.2093\nEpoch 98/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6756 - loss: 0.1962 - val_accuracy: 0.6534 - val_loss: 0.2078\nEpoch 99/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6761 - loss: 0.1961 - val_accuracy: 0.6539 - val_loss: 0.2086\nEpoch 100/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6716 - loss: 0.1977 - val_accuracy: 0.6535 - val_loss: 0.2078\nEpoch 101/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6753 - loss: 0.1963 - val_accuracy: 0.6498 - val_loss: 0.2113\nEpoch 102/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6742 - loss: 0.1964 - val_accuracy: 0.6525 - val_loss: 0.2078\nEpoch 103/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6733 - loss: 0.1965 - val_accuracy: 0.6516 - val_loss: 0.2095\nEpoch 104/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6746 - loss: 0.1964 - val_accuracy: 0.6517 - val_loss: 0.2078\nEpoch 105/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6756 - loss: 0.1960 - val_accuracy: 0.6515 - val_loss: 0.2090\nEpoch 106/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6748 - loss: 0.1960 - val_accuracy: 0.6513 - val_loss: 0.2094\nEpoch 107/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6756 - loss: 0.1958 - val_accuracy: 0.6532 - val_loss: 0.2083\nEpoch 108/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6743 - loss: 0.1963 - val_accuracy: 0.6540 - val_loss: 0.2080\nEpoch 109/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6728 - loss: 0.1968 - val_accuracy: 0.6501 - val_loss: 0.2091\nEpoch 110/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6761 - loss: 0.1957 - val_accuracy: 0.6488 - val_loss: 0.2091\nEpoch 111/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6742 - loss: 0.1961 - val_accuracy: 0.6490 - val_loss: 0.2091\nEpoch 112/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6768 - loss: 0.1955 - val_accuracy: 0.6534 - val_loss: 0.2074\nEpoch 113/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6738 - loss: 0.1956 - val_accuracy: 0.6530 - val_loss: 0.2091\nEpoch 114/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6777 - loss: 0.1952 - val_accuracy: 0.6514 - val_loss: 0.2084\nEpoch 115/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6784 - loss: 0.1948 - val_accuracy: 0.6538 - val_loss: 0.2080\nEpoch 116/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6753 - loss: 0.1956 - val_accuracy: 0.6524 - val_loss: 0.2087\nEpoch 117/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.1948 - val_accuracy: 0.6550 - val_loss: 0.2062\nEpoch 118/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 0.1943 - val_accuracy: 0.6551 - val_loss: 0.2068\nEpoch 119/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6775 - loss: 0.1944 - val_accuracy: 0.6523 - val_loss: 0.2077\nEpoch 120/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6762 - loss: 0.1949 - val_accuracy: 0.6524 - val_loss: 0.2073\nEpoch 121/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6784 - loss: 0.1949 - val_accuracy: 0.6534 - val_loss: 0.2086\nEpoch 122/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6777 - loss: 0.1950 - val_accuracy: 0.6536 - val_loss: 0.2082\nEpoch 123/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6758 - loss: 0.1958 - val_accuracy: 0.6527 - val_loss: 0.2088\nEpoch 124/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6791 - loss: 0.1948 - val_accuracy: 0.6529 - val_loss: 0.2073\nEpoch 125/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6784 - loss: 0.1943 - val_accuracy: 0.6528 - val_loss: 0.2083\nEpoch 126/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6777 - loss: 0.1945 - val_accuracy: 0.6504 - val_loss: 0.2101\nEpoch 127/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6794 - loss: 0.1940 - val_accuracy: 0.6510 - val_loss: 0.2097\nEpoch 128/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6782 - loss: 0.1944 - val_accuracy: 0.6533 - val_loss: 0.2077\nEpoch 129/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6770 - loss: 0.1943 - val_accuracy: 0.6519 - val_loss: 0.2088\nEpoch 130/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6761 - loss: 0.1958 - val_accuracy: 0.6525 - val_loss: 0.2080\nEpoch 131/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6789 - loss: 0.1941 - val_accuracy: 0.6549 - val_loss: 0.2067\nEpoch 132/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.1946 - val_accuracy: 0.6549 - val_loss: 0.2072\nEpoch 133/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6787 - loss: 0.1944 - val_accuracy: 0.6539 - val_loss: 0.2077\nEpoch 134/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6782 - loss: 0.1943 - val_accuracy: 0.6529 - val_loss: 0.2075\nEpoch 135/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6761 - loss: 0.1945 - val_accuracy: 0.6562 - val_loss: 0.2070\nEpoch 136/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6782 - loss: 0.1945 - val_accuracy: 0.6529 - val_loss: 0.2082\nEpoch 137/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6778 - loss: 0.1943 - val_accuracy: 0.6526 - val_loss: 0.2079\nEpoch 138/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6775 - loss: 0.1948 - val_accuracy: 0.6540 - val_loss: 0.2076\nEpoch 139/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6810 - loss: 0.1944 - val_accuracy: 0.6558 - val_loss: 0.2078\nEpoch 140/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6774 - loss: 0.1945 - val_accuracy: 0.6525 - val_loss: 0.2085\nEpoch 141/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6766 - loss: 0.1946 - val_accuracy: 0.6525 - val_loss: 0.2084\nEpoch 142/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6799 - loss: 0.1941 - val_accuracy: 0.6511 - val_loss: 0.2096\nEpoch 143/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6799 - loss: 0.1940 - val_accuracy: 0.6554 - val_loss: 0.2076\nEpoch 144/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6800 - loss: 0.1940 - val_accuracy: 0.6530 - val_loss: 0.2080\nEpoch 145/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.1934 - val_accuracy: 0.6551 - val_loss: 0.2065\nEpoch 146/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6815 - loss: 0.1929 - val_accuracy: 0.6546 - val_loss: 0.2085\nEpoch 147/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6813 - loss: 0.1931 - val_accuracy: 0.6549 - val_loss: 0.2076\nEpoch 148/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6789 - loss: 0.1935 - val_accuracy: 0.6545 - val_loss: 0.2082\nEpoch 149/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6798 - loss: 0.1941 - val_accuracy: 0.6542 - val_loss: 0.2087\nEpoch 150/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6805 - loss: 0.1936 - val_accuracy: 0.6558 - val_loss: 0.2071\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\ny_ pred :  [[0.56014377]\n [0.5591824 ]\n [0.5610544 ]\n ...\n [0.5590223 ]\n [0.5590223 ]\n [0.5590223 ]]   -------  y_test :  [1 1 0 ... 0 0 0]\ny_pred astype :  [[1]\n [1]\n [1]\n ...\n [1]\n [1]\n [1]]\nFold 2:\n  Số lượng dự đoán là 0: 9202\n  Số lượng dự đoán là 1: 23822\n test Số lượng dự đoán là 0: 14816\n test Số lượng dự đoán là 1: 18208\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6424 - loss: 0.2175\nFold 2 Test Score:  [0.20711040496826172, 0.6558260917663574]\nFold 2 F1 Score:  0.7295741137282893\nTraining fold 3\nEpoch 1/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.5530 - loss: 0.2470 - val_accuracy: 0.5642 - val_loss: 0.2435\nEpoch 2/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.5743 - loss: 0.2420 - val_accuracy: 0.5842 - val_loss: 0.2391\nEpoch 3/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.5882 - loss: 0.2378 - val_accuracy: 0.5931 - val_loss: 0.2369\nEpoch 4/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.5957 - loss: 0.2354 - val_accuracy: 0.5908 - val_loss: 0.2353\nEpoch 5/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6000 - loss: 0.2334 - val_accuracy: 0.6019 - val_loss: 0.2329\nEpoch 6/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6072 - loss: 0.2310 - val_accuracy: 0.6025 - val_loss: 0.2312\nEpoch 7/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6090 - loss: 0.2295 - val_accuracy: 0.6097 - val_loss: 0.2291\nEpoch 8/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6123 - loss: 0.2282 - val_accuracy: 0.6116 - val_loss: 0.2278\nEpoch 9/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 0.2264 - val_accuracy: 0.6131 - val_loss: 0.2270\nEpoch 10/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6203 - loss: 0.2249 - val_accuracy: 0.6166 - val_loss: 0.2253\nEpoch 11/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6248 - loss: 0.2237 - val_accuracy: 0.6168 - val_loss: 0.2249\nEpoch 12/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6283 - loss: 0.2220 - val_accuracy: 0.6254 - val_loss: 0.2219\nEpoch 13/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6285 - loss: 0.2212 - val_accuracy: 0.6234 - val_loss: 0.2215\nEpoch 14/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6306 - loss: 0.2205 - val_accuracy: 0.6279 - val_loss: 0.2208\nEpoch 15/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6303 - loss: 0.2195 - val_accuracy: 0.6283 - val_loss: 0.2200\nEpoch 16/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6328 - loss: 0.2185 - val_accuracy: 0.6302 - val_loss: 0.2193\nEpoch 17/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6336 - loss: 0.2177 - val_accuracy: 0.6318 - val_loss: 0.2184\nEpoch 18/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6372 - loss: 0.2164 - val_accuracy: 0.6305 - val_loss: 0.2181\nEpoch 19/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6382 - loss: 0.2159 - val_accuracy: 0.6342 - val_loss: 0.2173\nEpoch 20/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6413 - loss: 0.2143 - val_accuracy: 0.6373 - val_loss: 0.2160\nEpoch 21/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6448 - loss: 0.2136 - val_accuracy: 0.6347 - val_loss: 0.2179\nEpoch 22/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6427 - loss: 0.2138 - val_accuracy: 0.6354 - val_loss: 0.2169\nEpoch 23/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6455 - loss: 0.2130 - val_accuracy: 0.6357 - val_loss: 0.2155\nEpoch 24/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6463 - loss: 0.2120 - val_accuracy: 0.6355 - val_loss: 0.2168\nEpoch 25/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6483 - loss: 0.2108 - val_accuracy: 0.6367 - val_loss: 0.2162\nEpoch 26/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6508 - loss: 0.2106 - val_accuracy: 0.6363 - val_loss: 0.2147\nEpoch 27/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6509 - loss: 0.2104 - val_accuracy: 0.6387 - val_loss: 0.2138\nEpoch 28/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6492 - loss: 0.2094 - val_accuracy: 0.6407 - val_loss: 0.2138\nEpoch 29/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6506 - loss: 0.2091 - val_accuracy: 0.6410 - val_loss: 0.2137\nEpoch 30/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6491 - loss: 0.2096 - val_accuracy: 0.6441 - val_loss: 0.2127\nEpoch 31/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6558 - loss: 0.2072 - val_accuracy: 0.6446 - val_loss: 0.2124\nEpoch 32/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6551 - loss: 0.2076 - val_accuracy: 0.6440 - val_loss: 0.2128\nEpoch 33/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6545 - loss: 0.2073 - val_accuracy: 0.6402 - val_loss: 0.2129\nEpoch 34/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6578 - loss: 0.2062 - val_accuracy: 0.6427 - val_loss: 0.2132\nEpoch 35/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6565 - loss: 0.2065 - val_accuracy: 0.6454 - val_loss: 0.2116\nEpoch 36/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6588 - loss: 0.2054 - val_accuracy: 0.6403 - val_loss: 0.2142\nEpoch 37/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6527 - loss: 0.2071 - val_accuracy: 0.6456 - val_loss: 0.2127\nEpoch 38/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6597 - loss: 0.2048 - val_accuracy: 0.6459 - val_loss: 0.2116\nEpoch 39/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6598 - loss: 0.2050 - val_accuracy: 0.6471 - val_loss: 0.2102\nEpoch 40/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6604 - loss: 0.2049 - val_accuracy: 0.6479 - val_loss: 0.2104\nEpoch 41/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6595 - loss: 0.2043 - val_accuracy: 0.6459 - val_loss: 0.2104\nEpoch 42/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6619 - loss: 0.2037 - val_accuracy: 0.6445 - val_loss: 0.2119\nEpoch 43/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6615 - loss: 0.2043 - val_accuracy: 0.6471 - val_loss: 0.2104\nEpoch 44/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6617 - loss: 0.2037 - val_accuracy: 0.6499 - val_loss: 0.2098\nEpoch 45/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6633 - loss: 0.2030 - val_accuracy: 0.6506 - val_loss: 0.2097\nEpoch 46/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6637 - loss: 0.2027 - val_accuracy: 0.6483 - val_loss: 0.2106\nEpoch 47/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6615 - loss: 0.2033 - val_accuracy: 0.6452 - val_loss: 0.2119\nEpoch 48/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6614 - loss: 0.2031 - val_accuracy: 0.6467 - val_loss: 0.2106\nEpoch 49/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6659 - loss: 0.2015 - val_accuracy: 0.6492 - val_loss: 0.2091\nEpoch 50/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6651 - loss: 0.2018 - val_accuracy: 0.6524 - val_loss: 0.2081\nEpoch 51/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6633 - loss: 0.2017 - val_accuracy: 0.6460 - val_loss: 0.2113\nEpoch 52/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6659 - loss: 0.2012 - val_accuracy: 0.6474 - val_loss: 0.2111\nEpoch 53/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6663 - loss: 0.2007 - val_accuracy: 0.6506 - val_loss: 0.2088\nEpoch 54/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6679 - loss: 0.2009 - val_accuracy: 0.6477 - val_loss: 0.2104\nEpoch 55/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6666 - loss: 0.2006 - val_accuracy: 0.6546 - val_loss: 0.2077\nEpoch 56/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6690 - loss: 0.2002 - val_accuracy: 0.6498 - val_loss: 0.2087\nEpoch 57/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6688 - loss: 0.2001 - val_accuracy: 0.6475 - val_loss: 0.2107\nEpoch 58/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6693 - loss: 0.2002 - val_accuracy: 0.6486 - val_loss: 0.2096\nEpoch 59/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6682 - loss: 0.1996 - val_accuracy: 0.6477 - val_loss: 0.2100\nEpoch 60/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6694 - loss: 0.1999 - val_accuracy: 0.6541 - val_loss: 0.2070\nEpoch 61/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6672 - loss: 0.2002 - val_accuracy: 0.6539 - val_loss: 0.2078\nEpoch 62/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6696 - loss: 0.1986 - val_accuracy: 0.6532 - val_loss: 0.2075\nEpoch 63/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6694 - loss: 0.1994 - val_accuracy: 0.6525 - val_loss: 0.2072\nEpoch 64/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6701 - loss: 0.1988 - val_accuracy: 0.6517 - val_loss: 0.2087\nEpoch 65/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6716 - loss: 0.1985 - val_accuracy: 0.6545 - val_loss: 0.2075\nEpoch 66/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6697 - loss: 0.1994 - val_accuracy: 0.6514 - val_loss: 0.2091\nEpoch 67/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6707 - loss: 0.1987 - val_accuracy: 0.6541 - val_loss: 0.2069\nEpoch 68/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6711 - loss: 0.1985 - val_accuracy: 0.6552 - val_loss: 0.2064\nEpoch 69/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6722 - loss: 0.1985 - val_accuracy: 0.6521 - val_loss: 0.2082\nEpoch 70/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6716 - loss: 0.1981 - val_accuracy: 0.6546 - val_loss: 0.2068\nEpoch 71/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6711 - loss: 0.1982 - val_accuracy: 0.6526 - val_loss: 0.2077\nEpoch 72/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6725 - loss: 0.1974 - val_accuracy: 0.6555 - val_loss: 0.2064\nEpoch 73/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6726 - loss: 0.1979 - val_accuracy: 0.6520 - val_loss: 0.2081\nEpoch 74/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6749 - loss: 0.1974 - val_accuracy: 0.6539 - val_loss: 0.2074\nEpoch 75/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6720 - loss: 0.1973 - val_accuracy: 0.6547 - val_loss: 0.2072\nEpoch 76/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6727 - loss: 0.1974 - val_accuracy: 0.6533 - val_loss: 0.2075\nEpoch 77/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6753 - loss: 0.1965 - val_accuracy: 0.6539 - val_loss: 0.2075\nEpoch 78/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6751 - loss: 0.1970 - val_accuracy: 0.6554 - val_loss: 0.2060\nEpoch 79/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6743 - loss: 0.1968 - val_accuracy: 0.6558 - val_loss: 0.2067\nEpoch 80/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6745 - loss: 0.1971 - val_accuracy: 0.6536 - val_loss: 0.2079\nEpoch 81/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6745 - loss: 0.1961 - val_accuracy: 0.6555 - val_loss: 0.2069\nEpoch 82/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6741 - loss: 0.1966 - val_accuracy: 0.6558 - val_loss: 0.2069\nEpoch 83/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6738 - loss: 0.1968 - val_accuracy: 0.6542 - val_loss: 0.2066\nEpoch 84/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.1959 - val_accuracy: 0.6555 - val_loss: 0.2060\nEpoch 85/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6748 - loss: 0.1962 - val_accuracy: 0.6536 - val_loss: 0.2075\nEpoch 86/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6754 - loss: 0.1956 - val_accuracy: 0.6559 - val_loss: 0.2061\nEpoch 87/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6750 - loss: 0.1962 - val_accuracy: 0.6542 - val_loss: 0.2077\nEpoch 88/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6764 - loss: 0.1957 - val_accuracy: 0.6573 - val_loss: 0.2059\nEpoch 89/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6761 - loss: 0.1959 - val_accuracy: 0.6555 - val_loss: 0.2063\nEpoch 90/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6784 - loss: 0.1946 - val_accuracy: 0.6542 - val_loss: 0.2067\nEpoch 91/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6754 - loss: 0.1960 - val_accuracy: 0.6562 - val_loss: 0.2062\nEpoch 92/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6756 - loss: 0.1961 - val_accuracy: 0.6536 - val_loss: 0.2080\nEpoch 93/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6760 - loss: 0.1957 - val_accuracy: 0.6529 - val_loss: 0.2067\nEpoch 94/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 0.1952 - val_accuracy: 0.6527 - val_loss: 0.2084\nEpoch 95/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6768 - loss: 0.1956 - val_accuracy: 0.6557 - val_loss: 0.2066\nEpoch 96/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6760 - loss: 0.1950 - val_accuracy: 0.6548 - val_loss: 0.2078\nEpoch 97/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.1951 - val_accuracy: 0.6558 - val_loss: 0.2061\nEpoch 98/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.1950 - val_accuracy: 0.6549 - val_loss: 0.2078\nEpoch 99/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6774 - loss: 0.1953 - val_accuracy: 0.6565 - val_loss: 0.2064\nEpoch 100/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6761 - loss: 0.1953 - val_accuracy: 0.6546 - val_loss: 0.2075\nEpoch 101/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6738 - loss: 0.1961 - val_accuracy: 0.6546 - val_loss: 0.2067\nEpoch 102/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6774 - loss: 0.1956 - val_accuracy: 0.6518 - val_loss: 0.2082\nEpoch 103/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6794 - loss: 0.1945 - val_accuracy: 0.6559 - val_loss: 0.2057\nEpoch 104/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6794 - loss: 0.1937 - val_accuracy: 0.6565 - val_loss: 0.2064\nEpoch 105/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6808 - loss: 0.1936 - val_accuracy: 0.6545 - val_loss: 0.2076\nEpoch 106/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6795 - loss: 0.1947 - val_accuracy: 0.6599 - val_loss: 0.2062\nEpoch 107/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6797 - loss: 0.1941 - val_accuracy: 0.6582 - val_loss: 0.2056\nEpoch 108/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6800 - loss: 0.1943 - val_accuracy: 0.6560 - val_loss: 0.2077\nEpoch 109/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6796 - loss: 0.1941 - val_accuracy: 0.6577 - val_loss: 0.2065\nEpoch 110/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6786 - loss: 0.1943 - val_accuracy: 0.6566 - val_loss: 0.2069\nEpoch 111/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6801 - loss: 0.1935 - val_accuracy: 0.6581 - val_loss: 0.2057\nEpoch 112/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6829 - loss: 0.1931 - val_accuracy: 0.6546 - val_loss: 0.2075\nEpoch 113/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6802 - loss: 0.1931 - val_accuracy: 0.6588 - val_loss: 0.2061\nEpoch 114/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.1944 - val_accuracy: 0.6599 - val_loss: 0.2050\nEpoch 115/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6793 - loss: 0.1939 - val_accuracy: 0.6560 - val_loss: 0.2063\nEpoch 116/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6820 - loss: 0.1938 - val_accuracy: 0.6583 - val_loss: 0.2060\nEpoch 117/150\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6802 - loss: 0.1932 - val_accuracy: 0.6526 - val_loss: 0.2097\nEpoch 118/150\n\u001b[1m 745/4128\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.6783 - loss: 0.1942","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean_f1_score = np.mean(f1_scores)\nstd_f1_score = np.std(f1_scores)\n\n# Log the mean and std F1-score\nwandb.log({\n    \"mean_f1_score\": mean_f1_score,\n    \"std_f1_score\": std_f1_score\n})\nwandb.finish()\n\nprint(f\"Mean F1 Score: {mean_f1_score}\")\nprint(f\"Standard Deviation of F1 Score: {std_f1_score}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T08:14:37.750462Z","iopub.status.idle":"2024-12-15T08:14:37.750967Z","shell.execute_reply.started":"2024-12-15T08:14:37.750708Z","shell.execute_reply":"2024-12-15T08:14:37.750736Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}