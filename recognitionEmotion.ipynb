{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7420888,"sourceType":"datasetVersion","datasetId":4317501}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Flatten, Dense, Input, LSTM, Dropout\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nimport seaborn as sns\nfrom scipy.signal import welch\nfrom scipy.stats import entropy, skew, kurtosis\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import LabelBinarizer","metadata":{"execution":{"iopub.status.busy":"2024-12-14T15:22:29.746758Z","iopub.execute_input":"2024-12-14T15:22:29.747010Z","iopub.status.idle":"2024-12-14T15:22:41.946649Z","shell.execute_reply.started":"2024-12-14T15:22:29.746982Z","shell.execute_reply":"2024-12-14T15:22:41.945733Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2024-12-14 15:22:31.579323: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-12-14 15:22:31.579430: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-12-14 15:22:31.718755: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\ndef read_data(filename):\n    with open(filename, 'rb') as f:\n        data = pickle.load(f, encoding='latin1')\n    return data\n\nfiles = [f\"s{n:02d}\" for n in range(1, 33)]\n\nlabels, data = [], []\n\nfor file in files:\n    filepath = f\"/kaggle/input/deap-dataset/data_preprocessed_python/{file}.dat\"\n    d = read_data(filepath)\n    labels.append(d['labels'])\n    data.append(d['data'])\n\nlabels = np.array(labels)\ndata = np.array(data)\n\nprint(\"Labels shape: \", labels.shape)\nprint(\"Data shape: \", data.shape)\n\neeg_data = data[:, :, :32, -7680:]\nprint(\"EEG data shape: \", eeg_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-12-14T15:24:55.818543Z","iopub.execute_input":"2024-12-14T15:24:55.818935Z","iopub.status.idle":"2024-12-14T15:25:06.347237Z","shell.execute_reply.started":"2024-12-14T15:24:55.818908Z","shell.execute_reply":"2024-12-14T15:25:06.346359Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Labels shape:  (32, 40, 4)\nData shape:  (32, 40, 40, 8064)\nEEG data shape:  (32, 40, 32, 7680)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def extract_psd_feature(data):\n    psd_features = []\n    for channel_data in data:\n        f, psd = welch(channel_data, fs=128)\n        psd_features.append(psd)\n    return np.array(psd_features)\n\ndef extract_entropy_feature(data):\n    entropy_features = []\n    for channel_data in data:\n        prob_dist, _ = np.histogram(channel_data, bins=128, density=True)\n        prob_dist = prob_dist / np.sum(prob_dist)\n        entropy_features.append(entropy(prob_dist))\n    return np.array(entropy_features)\n\ndef extract_sd_feature(data):\n    return np.std(data, axis=1)\n\ndef extract_mean_feature(data):\n    return np.mean(data, axis=1)\ndef extract_variance_feature(data):\n    return np.var(data, axis=1)\n\ndef extract_skewness_feature(data):\n    return skew(data, axis=1)\n\ndef extract_kurtosis_feature(data):\n    return kurtosis(data, axis=1)\n\ndef preprocess_data(eeg_data, labels, feature_type):\n    data_features, data_labels, data_labels_valence = [], [], []\n    \n    for subject in range(eeg_data.shape[0]):\n        for trial in range(eeg_data.shape[1]):\n            trial_data = eeg_data[subject, trial, :, :]\n            if feature_type == 'psd':\n                features = extract_psd_feature(trial_data)\n            elif feature_type == 'entropy':\n                features = extract_entropy_feature(trial_data)\n            elif feature_type == 'sd':\n                features = extract_sd_feature(trial_data)\n            elif feature_type == 'mean':\n                features = extract_mean_feature(trial_data)\n            elif feature_type == 'variance':\n                features = extract_variance_feature(trial_data)\n            elif feature_type == 'skewness':\n                features = extract_skewness_feature(trial_data)\n            elif feature_type == 'kurtosis':\n                features = extract_kurtosis_feature(trial_data)\n            else:\n                raise ValueError(\"Unknown feature type\")\n            \n            data_features.append(features)\n            arousal_label = labels[subject, trial, 0]\n            data_labels.append(1 if arousal_label > 5 else 0)\n            valence_label = labels[subject, trial, 1]\n            data_labels_valence.append(1 if valence_label > 5 else 0)\n    \n    return np.array(data_features), np.array(data_labels), np.array(data_labels_valence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:25:06.348604Z","iopub.execute_input":"2024-12-14T15:25:06.348881Z","iopub.status.idle":"2024-12-14T15:25:06.358637Z","shell.execute_reply.started":"2024-12-14T15:25:06.348861Z","shell.execute_reply":"2024-12-14T15:25:06.357767Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"feature_types = ['psd', 'entropy', 'sd', 'mean', 'variance', 'skewness', 'kurtosis']\n\nall_features = {}\nfor feature_type in feature_types:\n    features, labels_processed, labels_processed_valence = preprocess_data(eeg_data, labels, feature_type)\n    all_features[feature_type] = (features, labels_processed, labels_processed_valence)\n    print(f\"{feature_type.capitalize()} Features shape: \", features.shape)\n    print(f\"{feature_type.capitalize()} Arousal Labels shape: \", labels_processed.shape)\n    print(f\"{feature_type.capitalize()} Valence Labels shape: \", labels_processed_valence.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:25:06.359658Z","iopub.execute_input":"2024-12-14T15:25:06.360275Z","iopub.status.idle":"2024-12-14T15:25:39.658213Z","shell.execute_reply.started":"2024-12-14T15:25:06.360234Z","shell.execute_reply":"2024-12-14T15:25:39.657337Z"}},"outputs":[{"name":"stdout","text":"Psd Features shape:  (1280, 32, 129)\nPsd Arousal Labels shape:  (1280,)\nPsd Valence Labels shape:  (1280,)\nEntropy Features shape:  (1280, 32)\nEntropy Arousal Labels shape:  (1280,)\nEntropy Valence Labels shape:  (1280,)\nSd Features shape:  (1280, 32)\nSd Arousal Labels shape:  (1280,)\nSd Valence Labels shape:  (1280,)\nMean Features shape:  (1280, 32)\nMean Arousal Labels shape:  (1280,)\nMean Valence Labels shape:  (1280,)\nVariance Features shape:  (1280, 32)\nVariance Arousal Labels shape:  (1280,)\nVariance Valence Labels shape:  (1280,)\nSkewness Features shape:  (1280, 32)\nSkewness Arousal Labels shape:  (1280,)\nSkewness Valence Labels shape:  (1280,)\nKurtosis Features shape:  (1280, 32)\nKurtosis Arousal Labels shape:  (1280,)\nKurtosis Valence Labels shape:  (1280,)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# CNN + LSTM\ndef create_cnn_lstm_model(input_shape):\n    inputs = Input(shape=input_shape)\n    \n    # 1st Conv Block\n    x = Conv1D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n    x = BatchNormalization()(x)\n    x = MaxPooling1D(pool_size=2)(x)\n    \n    # 2nd Conv Block\n    x = Conv1D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling1D(pool_size=2)(x)\n    \n    # 3rd Conv Block \n    x = Conv1D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling1D(pool_size=2)(x)\n    \n    # LSTM\n    x = LSTM(256, return_sequences=False)(x)\n    \n    x = Dense(units=512, activation='relu')(x)\n    x = Dropout(0.5)(x)  \n    x = Dense(units=256, activation='relu')(x)\n    \n    outputs = Dense(units=1, activation='sigmoid')(x)\n    \n    \n    model = Model(inputs, outputs)\n    return model\n\nfeature_types = ['psd']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:25:39.659897Z","iopub.execute_input":"2024-12-14T15:25:39.660182Z","iopub.status.idle":"2024-12-14T15:25:39.667052Z","shell.execute_reply.started":"2024-12-14T15:25:39.660145Z","shell.execute_reply":"2024-12-14T15:25:39.666098Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nX_all = []\ny_all = []\n\nfor feature_type in feature_types:\n    features, arousal_labels, _ = all_features[feature_type]\n    \n    for channel in range(features.shape[2]):\n        channel_data = features[:, :, channel]  \n        X_all.append(channel_data)\n        y_all.append(arousal_labels)\n\nX_all = np.concatenate(X_all, axis=0)  \ny_all = np.concatenate(y_all, axis=0)  \n\nprint(\"Concatenated Features Shape: \", X_all.shape)\nprint(\"Concatenated Arousal Labels Shape: \", y_all.shape)\n\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:25:39.668129Z","iopub.execute_input":"2024-12-14T15:25:39.668367Z","iopub.status.idle":"2024-12-14T15:25:39.714551Z","shell.execute_reply.started":"2024-12-14T15:25:39.668349Z","shell.execute_reply":"2024-12-14T15:25:39.713655Z"}},"outputs":[{"name":"stdout","text":"Concatenated Features Shape:  (165120, 32)\nConcatenated Arousal Labels Shape:  (165120,)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os\nimport wandb\n\n# Đọc API key từ biến môi trường\napi_key = os.environ.get(\"88aea2f639fada32b4501731dc07e972dc732128\")\nwandb.login(key=api_key)\nwandb.init(project=\"Recognition Emotion\", config={\n               \"learning_rate\": 0.001,\n               \"epochs\": 150,\n               \"batch_size\": 32,\n               \"feature_type\": \"psd\", # Sẽ được cập nhật sau\n               \"model\": \"CNN-LSTM\"\n           })\nconfig={\n               \"learning_rate\": 0.001,\n               \"epochs\": 70,\n               \"batch_size\": 32,\n               \"feature_type\": \"psd\", # Sẽ được cập nhật sau\n               \"model\": \"CNN-LSTM\"\n           }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T16:37:43.402557Z","iopub.execute_input":"2024-12-14T16:37:43.403080Z","iopub.status.idle":"2024-12-14T16:38:04.505760Z","shell.execute_reply.started":"2024-12-14T16:37:43.403040Z","shell.execute_reply":"2024-12-14T16:38:04.504823Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:4smc9mfi) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f21b510b86744d0381d8f777ee423a91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁</td></tr><tr><td>fold</td><td>▁▁▃▅▆█</td></tr><tr><td>test/f1_score</td><td>▄▆▇▁█▆</td></tr><tr><td>test/fold</td><td>▁▁▃▅▆█</td></tr><tr><td>train/accuracy</td><td>▁▂█▄▄▂</td></tr><tr><td>train/loss</td><td>█▆▁█▄▆</td></tr><tr><td>val/accuracy</td><td>▁▁▃██▆</td></tr><tr><td>val/loss</td><td>█▇▃▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>fold</td><td>4</td></tr><tr><td>test/f1_score</td><td>0.71024</td></tr><tr><td>test/fold</td><td>4</td></tr><tr><td>train/accuracy</td><td>0.5561</td></tr><tr><td>train/loss</td><td>0.68553</td></tr><tr><td>val/accuracy</td><td>0.5642</td></tr><tr><td>val/loss</td><td>0.6813</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">glamorous-vortex-4</strong> at: <a href='https://wandb.ai/trangdo/Recognition%20Emotion/runs/4smc9mfi' target=\"_blank\">https://wandb.ai/trangdo/Recognition%20Emotion/runs/4smc9mfi</a><br/> View project at: <a href='https://wandb.ai/trangdo/Recognition%20Emotion' target=\"_blank\">https://wandb.ai/trangdo/Recognition%20Emotion</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241214_163117-4smc9mfi/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:4smc9mfi). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.19.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241214_163743-k3lypblz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/trangdo/Recognition%20Emotion/runs/k3lypblz' target=\"_blank\">winter-firefly-5</a></strong> to <a href='https://wandb.ai/trangdo/Recognition%20Emotion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/trangdo/Recognition%20Emotion' target=\"_blank\">https://wandb.ai/trangdo/Recognition%20Emotion</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/trangdo/Recognition%20Emotion/runs/k3lypblz' target=\"_blank\">https://wandb.ai/trangdo/Recognition%20Emotion/runs/k3lypblz</a>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    history = model.fit(X_train, y_train, epochs=config[\"epochs\"], batch_size=32, validation_data=(X_test, y_test), verbose=1)\n\n    for epoch in range(config[\"epochs\"]):\n        wandb.log({\n            \"epoch\": epoch,\n            \"train/loss\": history.history['loss'][epoch],\n            \"train/accuracy\": history.history['accuracy'][epoch],\n            \"val/loss\": history.history['val_loss'][epoch],\n            \"val/accuracy\": history.history['val_accuracy'][epoch],\n            \"fold\": fold\n        })\n    y_pred = model.predict(X_test)\n    y_pred = (y_pred > 0.5).astype(int)\n\n    f1 = f1_score(y_test, y_pred)\n    \n    test_score = model.evaluate(X_test, y_test)\n\n    wandb.log({\"test/f1_score\": f1, \"test/fold\": fold})\n\n    \n    return test_score, f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T16:39:48.585566Z","iopub.execute_input":"2024-12-14T16:39:48.586524Z","iopub.status.idle":"2024-12-14T16:39:48.596637Z","shell.execute_reply.started":"2024-12-14T16:39:48.586483Z","shell.execute_reply":"2024-12-14T16:39:48.595704Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# from wandb.keras import WandbCallback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T16:39:49.930747Z","iopub.execute_input":"2024-12-14T16:39:49.931320Z","iopub.status.idle":"2024-12-14T16:39:49.935939Z","shell.execute_reply.started":"2024-12-14T16:39:49.931291Z","shell.execute_reply":"2024-12-14T16:39:49.935048Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"for fold, (train_idx, val_idx) in enumerate(kf.split(X_all)):\n    print(f\"Training fold {fold + 1}\")\n    \n    X_train, X_val = X_all[train_idx], X_all[val_idx]\n    y_train, y_val = y_all[train_idx], y_all[val_idx]\n    \n    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n    \n    # CNN + LSTM\n    input_shape = (X_train.shape[1], 1)\n    model = create_cnn_lstm_model(input_shape)\n    \n    test_score, f1 = train_and_evaluate(model, X_train, y_train, X_val, y_val)\n    \n    print(f\"Fold {fold + 1} Test Score: \", test_score)\n    print(f\"Fold {fold + 1} F1 Score: \", f1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T16:39:50.683499Z","iopub.execute_input":"2024-12-14T16:39:50.683834Z","iopub.status.idle":"2024-12-14T19:45:49.509934Z","shell.execute_reply.started":"2024-12-14T16:39:50.683808Z","shell.execute_reply":"2024-12-14T19:45:49.509069Z"}},"outputs":[{"name":"stdout","text":"Training fold 1\nEpoch 1/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7ms/step - accuracy: 0.5494 - loss: 0.6904 - val_accuracy: 0.5759 - val_loss: 0.6807\nEpoch 2/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.5822 - loss: 0.6726 - val_accuracy: 0.5610 - val_loss: 0.6889\nEpoch 3/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.5937 - loss: 0.6608 - val_accuracy: 0.5659 - val_loss: 0.6877\nEpoch 4/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6078 - loss: 0.6485 - val_accuracy: 0.5568 - val_loss: 0.6868\nEpoch 5/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6147 - loss: 0.6394 - val_accuracy: 0.5659 - val_loss: 0.6869\nEpoch 6/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6280 - loss: 0.6275 - val_accuracy: 0.5720 - val_loss: 0.6872\nEpoch 7/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6316 - loss: 0.6209 - val_accuracy: 0.5774 - val_loss: 0.6768\nEpoch 8/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6392 - loss: 0.6150 - val_accuracy: 0.5712 - val_loss: 0.7169\nEpoch 9/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6441 - loss: 0.6072 - val_accuracy: 0.5779 - val_loss: 0.6808\nEpoch 10/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6464 - loss: 0.6007 - val_accuracy: 0.5808 - val_loss: 0.6924\nEpoch 11/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6471 - loss: 0.5971 - val_accuracy: 0.5655 - val_loss: 0.6972\nEpoch 12/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6532 - loss: 0.5908 - val_accuracy: 0.5786 - val_loss: 0.6938\nEpoch 13/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6573 - loss: 0.5853 - val_accuracy: 0.5692 - val_loss: 0.6866\nEpoch 14/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6622 - loss: 0.5797 - val_accuracy: 0.5794 - val_loss: 0.6838\nEpoch 15/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6633 - loss: 0.5767 - val_accuracy: 0.5800 - val_loss: 0.6849\nEpoch 16/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6662 - loss: 0.5723 - val_accuracy: 0.5630 - val_loss: 0.7292\nEpoch 17/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6655 - loss: 0.5722 - val_accuracy: 0.5837 - val_loss: 0.6759\nEpoch 18/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6688 - loss: 0.5679 - val_accuracy: 0.5820 - val_loss: 0.6751\nEpoch 19/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6728 - loss: 0.5638 - val_accuracy: 0.5754 - val_loss: 0.6803\nEpoch 20/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6728 - loss: 0.5605 - val_accuracy: 0.5802 - val_loss: 0.6908\nEpoch 21/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6739 - loss: 0.5578 - val_accuracy: 0.5918 - val_loss: 0.6778\nEpoch 22/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6738 - loss: 0.5563 - val_accuracy: 0.5786 - val_loss: 0.6752\nEpoch 23/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6786 - loss: 0.5536 - val_accuracy: 0.5789 - val_loss: 0.6890\nEpoch 24/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6778 - loss: 0.5517 - val_accuracy: 0.5833 - val_loss: 0.6917\nEpoch 25/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6825 - loss: 0.5469 - val_accuracy: 0.5801 - val_loss: 0.6963\nEpoch 26/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6801 - loss: 0.5474 - val_accuracy: 0.5813 - val_loss: 0.7205\nEpoch 27/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6856 - loss: 0.5424 - val_accuracy: 0.5801 - val_loss: 0.6826\nEpoch 28/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6853 - loss: 0.5426 - val_accuracy: 0.5779 - val_loss: 0.6998\nEpoch 29/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6879 - loss: 0.5381 - val_accuracy: 0.5745 - val_loss: 0.7185\nEpoch 30/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6879 - loss: 0.5354 - val_accuracy: 0.5906 - val_loss: 0.6754\nEpoch 31/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6874 - loss: 0.5366 - val_accuracy: 0.5873 - val_loss: 0.6761\nEpoch 32/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6906 - loss: 0.5312 - val_accuracy: 0.5883 - val_loss: 0.6647\nEpoch 33/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6927 - loss: 0.5294 - val_accuracy: 0.6052 - val_loss: 0.6639\nEpoch 34/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6936 - loss: 0.5291 - val_accuracy: 0.5983 - val_loss: 0.6648\nEpoch 35/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6944 - loss: 0.5252 - val_accuracy: 0.5972 - val_loss: 0.6675\nEpoch 36/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6956 - loss: 0.5238 - val_accuracy: 0.5822 - val_loss: 0.6915\nEpoch 37/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6982 - loss: 0.5227 - val_accuracy: 0.5860 - val_loss: 0.6929\nEpoch 38/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6981 - loss: 0.5215 - val_accuracy: 0.6045 - val_loss: 0.6491\nEpoch 39/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6965 - loss: 0.5200 - val_accuracy: 0.5923 - val_loss: 0.6806\nEpoch 40/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6953 - loss: 0.5229 - val_accuracy: 0.6087 - val_loss: 0.6568\nEpoch 41/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7003 - loss: 0.5165 - val_accuracy: 0.5918 - val_loss: 0.6813\nEpoch 42/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6992 - loss: 0.5158 - val_accuracy: 0.6292 - val_loss: 0.6330\nEpoch 43/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7019 - loss: 0.5115 - val_accuracy: 0.6020 - val_loss: 0.6669\nEpoch 44/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7015 - loss: 0.5135 - val_accuracy: 0.6130 - val_loss: 0.6625\nEpoch 45/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7021 - loss: 0.5129 - val_accuracy: 0.6005 - val_loss: 0.6753\nEpoch 46/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.7030 - loss: 0.5105 - val_accuracy: 0.6228 - val_loss: 0.6351\nEpoch 47/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7052 - loss: 0.5114 - val_accuracy: 0.6086 - val_loss: 0.6623\nEpoch 48/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.7056 - loss: 0.5073 - val_accuracy: 0.6081 - val_loss: 0.6506\nEpoch 49/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7050 - loss: 0.5064 - val_accuracy: 0.6080 - val_loss: 0.6543\nEpoch 50/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7103 - loss: 0.5027 - val_accuracy: 0.6104 - val_loss: 0.6614\nEpoch 51/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7090 - loss: 0.5039 - val_accuracy: 0.6161 - val_loss: 0.6542\nEpoch 52/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7105 - loss: 0.4995 - val_accuracy: 0.6203 - val_loss: 0.6438\nEpoch 53/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7087 - loss: 0.5035 - val_accuracy: 0.6249 - val_loss: 0.6390\nEpoch 54/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7085 - loss: 0.4999 - val_accuracy: 0.6143 - val_loss: 0.6470\nEpoch 55/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7116 - loss: 0.4986 - val_accuracy: 0.6129 - val_loss: 0.6516\nEpoch 56/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7093 - loss: 0.5024 - val_accuracy: 0.6375 - val_loss: 0.6340\nEpoch 57/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7120 - loss: 0.4949 - val_accuracy: 0.6199 - val_loss: 0.6603\nEpoch 58/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7139 - loss: 0.4949 - val_accuracy: 0.6143 - val_loss: 0.6688\nEpoch 59/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7120 - loss: 0.4928 - val_accuracy: 0.6057 - val_loss: 0.6842\nEpoch 60/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7162 - loss: 0.4911 - val_accuracy: 0.6071 - val_loss: 0.6674\nEpoch 61/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7159 - loss: 0.4917 - val_accuracy: 0.6376 - val_loss: 0.6225\nEpoch 62/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7171 - loss: 0.4911 - val_accuracy: 0.6331 - val_loss: 0.6319\nEpoch 63/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7189 - loss: 0.4886 - val_accuracy: 0.6151 - val_loss: 0.6650\nEpoch 64/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7182 - loss: 0.4879 - val_accuracy: 0.6217 - val_loss: 0.6478\nEpoch 65/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7190 - loss: 0.4857 - val_accuracy: 0.6362 - val_loss: 0.6327\nEpoch 66/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7176 - loss: 0.4887 - val_accuracy: 0.6398 - val_loss: 0.6125\nEpoch 67/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7207 - loss: 0.4834 - val_accuracy: 0.6411 - val_loss: 0.6298\nEpoch 68/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7175 - loss: 0.4838 - val_accuracy: 0.6427 - val_loss: 0.6113\nEpoch 69/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7245 - loss: 0.4777 - val_accuracy: 0.6341 - val_loss: 0.6424\nEpoch 70/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.7213 - loss: 0.4831 - val_accuracy: 0.6245 - val_loss: 0.6487\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6106 - loss: 0.6685\nFold 1 Test Score:  [0.6486583948135376, 0.624454915523529]\nFold 1 F1 Score:  0.6969356336444943\nTraining fold 2\nEpoch 1/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.5466 - loss: 0.6905 - val_accuracy: 0.5676 - val_loss: 0.6788\nEpoch 2/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.5817 - loss: 0.6732 - val_accuracy: 0.5786 - val_loss: 0.6730\nEpoch 3/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.5923 - loss: 0.6631 - val_accuracy: 0.5713 - val_loss: 0.6730\nEpoch 4/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 8ms/step - accuracy: 0.6030 - loss: 0.6509 - val_accuracy: 0.5830 - val_loss: 0.6691\nEpoch 5/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 8ms/step - accuracy: 0.6153 - loss: 0.6381 - val_accuracy: 0.5914 - val_loss: 0.6591\nEpoch 6/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6218 - loss: 0.6285 - val_accuracy: 0.5927 - val_loss: 0.6559\nEpoch 7/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6329 - loss: 0.6193 - val_accuracy: 0.6019 - val_loss: 0.6561\nEpoch 8/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6436 - loss: 0.6089 - val_accuracy: 0.5930 - val_loss: 0.6585\nEpoch 9/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6435 - loss: 0.6026 - val_accuracy: 0.6014 - val_loss: 0.6537\nEpoch 10/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6500 - loss: 0.5943 - val_accuracy: 0.5949 - val_loss: 0.6642\nEpoch 11/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6522 - loss: 0.5899 - val_accuracy: 0.6134 - val_loss: 0.6376\nEpoch 12/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6605 - loss: 0.5825 - val_accuracy: 0.6256 - val_loss: 0.6296\nEpoch 13/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6618 - loss: 0.5765 - val_accuracy: 0.6197 - val_loss: 0.6338\nEpoch 14/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6650 - loss: 0.5730 - val_accuracy: 0.6274 - val_loss: 0.6262\nEpoch 15/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6683 - loss: 0.5684 - val_accuracy: 0.6251 - val_loss: 0.6299\nEpoch 16/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6730 - loss: 0.5622 - val_accuracy: 0.6269 - val_loss: 0.6236\nEpoch 17/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6736 - loss: 0.5601 - val_accuracy: 0.6058 - val_loss: 0.6599\nEpoch 18/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6752 - loss: 0.5551 - val_accuracy: 0.6327 - val_loss: 0.6274\nEpoch 19/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6763 - loss: 0.5541 - val_accuracy: 0.6257 - val_loss: 0.6285\nEpoch 20/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.6839 - loss: 0.5453 - val_accuracy: 0.6420 - val_loss: 0.6057\nEpoch 21/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.6839 - loss: 0.5434 - val_accuracy: 0.6431 - val_loss: 0.6018\nEpoch 22/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.6789 - loss: 0.5445 - val_accuracy: 0.6471 - val_loss: 0.5999\nEpoch 23/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.6875 - loss: 0.5385 - val_accuracy: 0.6531 - val_loss: 0.5875\nEpoch 24/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6885 - loss: 0.5340 - val_accuracy: 0.6370 - val_loss: 0.6124\nEpoch 25/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6892 - loss: 0.5340 - val_accuracy: 0.6444 - val_loss: 0.6026\nEpoch 26/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6891 - loss: 0.5311 - val_accuracy: 0.6546 - val_loss: 0.5959\nEpoch 27/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6927 - loss: 0.5284 - val_accuracy: 0.6551 - val_loss: 0.5815\nEpoch 28/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6945 - loss: 0.5268 - val_accuracy: 0.6562 - val_loss: 0.5855\nEpoch 29/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6964 - loss: 0.5253 - val_accuracy: 0.6540 - val_loss: 0.5924\nEpoch 30/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6999 - loss: 0.5194 - val_accuracy: 0.6644 - val_loss: 0.5755\nEpoch 31/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7005 - loss: 0.5166 - val_accuracy: 0.6622 - val_loss: 0.5770\nEpoch 32/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7001 - loss: 0.5171 - val_accuracy: 0.6513 - val_loss: 0.5926\nEpoch 33/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7000 - loss: 0.5141 - val_accuracy: 0.6640 - val_loss: 0.5778\nEpoch 34/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7013 - loss: 0.5122 - val_accuracy: 0.6645 - val_loss: 0.5788\nEpoch 35/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7035 - loss: 0.5087 - val_accuracy: 0.6686 - val_loss: 0.5665\nEpoch 36/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7068 - loss: 0.5095 - val_accuracy: 0.6626 - val_loss: 0.5840\nEpoch 37/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7057 - loss: 0.5068 - val_accuracy: 0.6723 - val_loss: 0.5661\nEpoch 38/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7086 - loss: 0.5037 - val_accuracy: 0.6727 - val_loss: 0.5726\nEpoch 39/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7088 - loss: 0.5030 - val_accuracy: 0.6706 - val_loss: 0.5709\nEpoch 40/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7077 - loss: 0.5031 - val_accuracy: 0.6667 - val_loss: 0.5757\nEpoch 41/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7097 - loss: 0.4990 - val_accuracy: 0.6744 - val_loss: 0.5684\nEpoch 42/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7121 - loss: 0.4955 - val_accuracy: 0.6774 - val_loss: 0.5639\nEpoch 43/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7140 - loss: 0.4951 - val_accuracy: 0.6729 - val_loss: 0.5691\nEpoch 44/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7134 - loss: 0.4929 - val_accuracy: 0.6795 - val_loss: 0.5591\nEpoch 45/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7158 - loss: 0.4908 - val_accuracy: 0.6756 - val_loss: 0.5673\nEpoch 46/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7154 - loss: 0.4877 - val_accuracy: 0.6735 - val_loss: 0.5787\nEpoch 47/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7158 - loss: 0.4884 - val_accuracy: 0.6763 - val_loss: 0.5721\nEpoch 48/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7167 - loss: 0.4883 - val_accuracy: 0.6746 - val_loss: 0.5762\nEpoch 49/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7185 - loss: 0.4842 - val_accuracy: 0.6686 - val_loss: 0.5819\nEpoch 50/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7210 - loss: 0.4817 - val_accuracy: 0.6822 - val_loss: 0.5639\nEpoch 51/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.7203 - loss: 0.4827 - val_accuracy: 0.6791 - val_loss: 0.5594\nEpoch 52/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7225 - loss: 0.4804 - val_accuracy: 0.6712 - val_loss: 0.5742\nEpoch 53/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7228 - loss: 0.4786 - val_accuracy: 0.6813 - val_loss: 0.5587\nEpoch 54/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7224 - loss: 0.4770 - val_accuracy: 0.6786 - val_loss: 0.5668\nEpoch 55/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7225 - loss: 0.4777 - val_accuracy: 0.6826 - val_loss: 0.5619\nEpoch 56/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7264 - loss: 0.4734 - val_accuracy: 0.6784 - val_loss: 0.5686\nEpoch 57/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7269 - loss: 0.4717 - val_accuracy: 0.6841 - val_loss: 0.5626\nEpoch 58/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7251 - loss: 0.4745 - val_accuracy: 0.6844 - val_loss: 0.5728\nEpoch 59/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7253 - loss: 0.4724 - val_accuracy: 0.6868 - val_loss: 0.5707\nEpoch 60/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7272 - loss: 0.4701 - val_accuracy: 0.6782 - val_loss: 0.6014\nEpoch 61/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7266 - loss: 0.4695 - val_accuracy: 0.6814 - val_loss: 0.5561\nEpoch 62/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7303 - loss: 0.4647 - val_accuracy: 0.6901 - val_loss: 0.5581\nEpoch 63/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7286 - loss: 0.4669 - val_accuracy: 0.6887 - val_loss: 0.5658\nEpoch 64/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7308 - loss: 0.4627 - val_accuracy: 0.6843 - val_loss: 0.5615\nEpoch 65/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7306 - loss: 0.4656 - val_accuracy: 0.6869 - val_loss: 0.5632\nEpoch 66/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7308 - loss: 0.4608 - val_accuracy: 0.6868 - val_loss: 0.5712\nEpoch 67/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7309 - loss: 0.4607 - val_accuracy: 0.6836 - val_loss: 0.5796\nEpoch 68/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7332 - loss: 0.4591 - val_accuracy: 0.6866 - val_loss: 0.5736\nEpoch 69/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7313 - loss: 0.4598 - val_accuracy: 0.6873 - val_loss: 0.5726\nEpoch 70/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7340 - loss: 0.4574 - val_accuracy: 0.6918 - val_loss: 0.5801\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6765 - loss: 0.6194\nFold 2 Test Score:  [0.5800781846046448, 0.6917998790740967]\nFold 2 F1 Score:  0.7551599711330287\nTraining fold 3\nEpoch 1/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 8ms/step - accuracy: 0.5485 - loss: 0.6904 - val_accuracy: 0.5555 - val_loss: 0.6871\nEpoch 2/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.5792 - loss: 0.6721 - val_accuracy: 0.5530 - val_loss: 0.6861\nEpoch 3/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.5960 - loss: 0.6581 - val_accuracy: 0.5567 - val_loss: 0.6818\nEpoch 4/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6073 - loss: 0.6492 - val_accuracy: 0.5553 - val_loss: 0.6867\nEpoch 5/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.6115 - loss: 0.6415 - val_accuracy: 0.5583 - val_loss: 0.6819\nEpoch 6/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.6213 - loss: 0.6329 - val_accuracy: 0.5590 - val_loss: 0.6815\nEpoch 7/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.6279 - loss: 0.6248 - val_accuracy: 0.5541 - val_loss: 0.6981\nEpoch 8/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6308 - loss: 0.6208 - val_accuracy: 0.5600 - val_loss: 0.6798\nEpoch 9/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6355 - loss: 0.6137 - val_accuracy: 0.5584 - val_loss: 0.7009\nEpoch 10/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6434 - loss: 0.6054 - val_accuracy: 0.5541 - val_loss: 0.7039\nEpoch 11/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6465 - loss: 0.6008 - val_accuracy: 0.5568 - val_loss: 0.6831\nEpoch 12/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6495 - loss: 0.5959 - val_accuracy: 0.5563 - val_loss: 0.6828\nEpoch 13/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6534 - loss: 0.5892 - val_accuracy: 0.5642 - val_loss: 0.6827\nEpoch 14/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6517 - loss: 0.5876 - val_accuracy: 0.5615 - val_loss: 0.6825\nEpoch 15/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6556 - loss: 0.5826 - val_accuracy: 0.5575 - val_loss: 0.6825\nEpoch 16/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6613 - loss: 0.5807 - val_accuracy: 0.5667 - val_loss: 0.6802\nEpoch 17/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6623 - loss: 0.5745 - val_accuracy: 0.5561 - val_loss: 0.6849\nEpoch 18/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6630 - loss: 0.5743 - val_accuracy: 0.5694 - val_loss: 0.6790\nEpoch 19/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6668 - loss: 0.5693 - val_accuracy: 0.5565 - val_loss: 0.6869\nEpoch 20/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6719 - loss: 0.5652 - val_accuracy: 0.5592 - val_loss: 0.6847\nEpoch 21/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6706 - loss: 0.5628 - val_accuracy: 0.5599 - val_loss: 0.6809\nEpoch 22/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6699 - loss: 0.5616 - val_accuracy: 0.5554 - val_loss: 0.6834\nEpoch 23/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6748 - loss: 0.5587 - val_accuracy: 0.5713 - val_loss: 0.6811\nEpoch 24/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6788 - loss: 0.5523 - val_accuracy: 0.5567 - val_loss: 0.6974\nEpoch 25/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6783 - loss: 0.5543 - val_accuracy: 0.5538 - val_loss: 0.6936\nEpoch 26/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6775 - loss: 0.5504 - val_accuracy: 0.5617 - val_loss: 0.7201\nEpoch 27/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6808 - loss: 0.5494 - val_accuracy: 0.5580 - val_loss: 0.6848\nEpoch 28/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6821 - loss: 0.5462 - val_accuracy: 0.5549 - val_loss: 0.6957\nEpoch 29/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6823 - loss: 0.5437 - val_accuracy: 0.5584 - val_loss: 0.6894\nEpoch 30/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6856 - loss: 0.5425 - val_accuracy: 0.5593 - val_loss: 0.6814\nEpoch 31/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6826 - loss: 0.5422 - val_accuracy: 0.5578 - val_loss: 0.6843\nEpoch 32/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6874 - loss: 0.5386 - val_accuracy: 0.5674 - val_loss: 0.6811\nEpoch 33/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6867 - loss: 0.5369 - val_accuracy: 0.5560 - val_loss: 0.6849\nEpoch 34/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.6892 - loss: 0.5349 - val_accuracy: 0.5596 - val_loss: 0.6981\nEpoch 35/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.6868 - loss: 0.5358 - val_accuracy: 0.5575 - val_loss: 0.6977\nEpoch 36/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6887 - loss: 0.5319 - val_accuracy: 0.5549 - val_loss: 0.6839\nEpoch 37/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6916 - loss: 0.5301 - val_accuracy: 0.5634 - val_loss: 0.6916\nEpoch 38/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6905 - loss: 0.5305 - val_accuracy: 0.5590 - val_loss: 0.6844\nEpoch 39/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.6948 - loss: 0.5291 - val_accuracy: 0.5575 - val_loss: 0.6833\nEpoch 40/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.6937 - loss: 0.5274 - val_accuracy: 0.5604 - val_loss: 0.6889\nEpoch 41/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6957 - loss: 0.5249 - val_accuracy: 0.5599 - val_loss: 0.6871\nEpoch 42/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6965 - loss: 0.5224 - val_accuracy: 0.5592 - val_loss: 0.6848\nEpoch 43/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6972 - loss: 0.5220 - val_accuracy: 0.5598 - val_loss: 0.6807\nEpoch 44/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6995 - loss: 0.5196 - val_accuracy: 0.5546 - val_loss: 0.6856\nEpoch 45/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6971 - loss: 0.5218 - val_accuracy: 0.5586 - val_loss: 0.7026\nEpoch 46/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6962 - loss: 0.5219 - val_accuracy: 0.5620 - val_loss: 0.6840\nEpoch 47/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6993 - loss: 0.5169 - val_accuracy: 0.5547 - val_loss: 0.6838\nEpoch 48/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7009 - loss: 0.5156 - val_accuracy: 0.5515 - val_loss: 0.6870\nEpoch 49/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7034 - loss: 0.5150 - val_accuracy: 0.5573 - val_loss: 0.6950\nEpoch 50/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7035 - loss: 0.5106 - val_accuracy: 0.5544 - val_loss: 0.6861\nEpoch 51/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7025 - loss: 0.5135 - val_accuracy: 0.5583 - val_loss: 0.6834\nEpoch 52/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7019 - loss: 0.5116 - val_accuracy: 0.5550 - val_loss: 0.6892\nEpoch 53/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7030 - loss: 0.5089 - val_accuracy: 0.5581 - val_loss: 0.6870\nEpoch 54/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7065 - loss: 0.5081 - val_accuracy: 0.5234 - val_loss: 0.6864\nEpoch 55/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7053 - loss: 0.5095 - val_accuracy: 0.5568 - val_loss: 0.6842\nEpoch 56/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7087 - loss: 0.5027 - val_accuracy: 0.5622 - val_loss: 0.6820\nEpoch 57/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7084 - loss: 0.5055 - val_accuracy: 0.5589 - val_loss: 0.6840\nEpoch 58/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7073 - loss: 0.5046 - val_accuracy: 0.5621 - val_loss: 0.6882\nEpoch 59/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7094 - loss: 0.5041 - val_accuracy: 0.5579 - val_loss: 0.6856\nEpoch 60/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7083 - loss: 0.5033 - val_accuracy: 0.5473 - val_loss: 0.6875\nEpoch 61/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7107 - loss: 0.5007 - val_accuracy: 0.5432 - val_loss: 0.6879\nEpoch 62/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7094 - loss: 0.5000 - val_accuracy: 0.5270 - val_loss: 0.6947\nEpoch 63/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7138 - loss: 0.4969 - val_accuracy: 0.5158 - val_loss: 0.6915\nEpoch 64/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7122 - loss: 0.4958 - val_accuracy: 0.5592 - val_loss: 0.6878\nEpoch 65/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7130 - loss: 0.5001 - val_accuracy: 0.5271 - val_loss: 0.6906\nEpoch 66/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7128 - loss: 0.4972 - val_accuracy: 0.5184 - val_loss: 0.7189\nEpoch 67/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7153 - loss: 0.4944 - val_accuracy: 0.5149 - val_loss: 0.6884\nEpoch 68/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7138 - loss: 0.4944 - val_accuracy: 0.5044 - val_loss: 0.6935\nEpoch 69/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7169 - loss: 0.4914 - val_accuracy: 0.5034 - val_loss: 0.6999\nEpoch 70/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.7150 - loss: 0.4949 - val_accuracy: 0.5240 - val_loss: 0.6959\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5379 - loss: 0.6939\nFold 3 Test Score:  [0.6958516240119934, 0.523952305316925]\nFold 3 F1 Score:  0.5643342108909519\nTraining fold 4\nEpoch 1/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.5490 - loss: 0.6897 - val_accuracy: 0.5567 - val_loss: 0.6823\nEpoch 2/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.5848 - loss: 0.6691 - val_accuracy: 0.5583 - val_loss: 0.6820\nEpoch 3/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.5973 - loss: 0.6552 - val_accuracy: 0.5855 - val_loss: 0.6694\nEpoch 4/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6070 - loss: 0.6473 - val_accuracy: 0.5772 - val_loss: 0.6760\nEpoch 5/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6137 - loss: 0.6390 - val_accuracy: 0.5638 - val_loss: 0.6884\nEpoch 6/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6255 - loss: 0.6285 - val_accuracy: 0.5937 - val_loss: 0.6688\nEpoch 7/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6313 - loss: 0.6206 - val_accuracy: 0.5809 - val_loss: 0.6761\nEpoch 8/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6378 - loss: 0.6119 - val_accuracy: 0.5809 - val_loss: 0.6737\nEpoch 9/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.6408 - loss: 0.6079 - val_accuracy: 0.5818 - val_loss: 0.6757\nEpoch 10/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6462 - loss: 0.6014 - val_accuracy: 0.5746 - val_loss: 0.6800\nEpoch 11/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6487 - loss: 0.5935 - val_accuracy: 0.5831 - val_loss: 0.6836\nEpoch 12/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6513 - loss: 0.5908 - val_accuracy: 0.5849 - val_loss: 0.6859\nEpoch 13/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6548 - loss: 0.5862 - val_accuracy: 0.5751 - val_loss: 0.6856\nEpoch 14/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6601 - loss: 0.5813 - val_accuracy: 0.5684 - val_loss: 0.6907\nEpoch 15/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6611 - loss: 0.5798 - val_accuracy: 0.5749 - val_loss: 0.6830\nEpoch 16/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6645 - loss: 0.5739 - val_accuracy: 0.5810 - val_loss: 0.6847\nEpoch 17/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6621 - loss: 0.5754 - val_accuracy: 0.5624 - val_loss: 0.7666\nEpoch 18/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6690 - loss: 0.5668 - val_accuracy: 0.5706 - val_loss: 0.6911\nEpoch 19/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6684 - loss: 0.5653 - val_accuracy: 0.5691 - val_loss: 0.7007\nEpoch 20/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6697 - loss: 0.5628 - val_accuracy: 0.5639 - val_loss: 0.7193\nEpoch 21/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6743 - loss: 0.5576 - val_accuracy: 0.5695 - val_loss: 0.7069\nEpoch 22/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6762 - loss: 0.5560 - val_accuracy: 0.5747 - val_loss: 0.6836\nEpoch 23/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6779 - loss: 0.5542 - val_accuracy: 0.5833 - val_loss: 0.6807\nEpoch 24/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6773 - loss: 0.5509 - val_accuracy: 0.5718 - val_loss: 0.7119\nEpoch 25/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6808 - loss: 0.5484 - val_accuracy: 0.5780 - val_loss: 0.6970\nEpoch 26/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6811 - loss: 0.5481 - val_accuracy: 0.5773 - val_loss: 0.6785\nEpoch 27/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6805 - loss: 0.5449 - val_accuracy: 0.5711 - val_loss: 0.7116\nEpoch 28/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6845 - loss: 0.5429 - val_accuracy: 0.5840 - val_loss: 0.6743\nEpoch 29/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6824 - loss: 0.5435 - val_accuracy: 0.5732 - val_loss: 0.6793\nEpoch 30/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6889 - loss: 0.5377 - val_accuracy: 0.5847 - val_loss: 0.6758\nEpoch 31/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6860 - loss: 0.5380 - val_accuracy: 0.5613 - val_loss: 0.6894\nEpoch 32/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6885 - loss: 0.5351 - val_accuracy: 0.5769 - val_loss: 0.6756\nEpoch 33/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6934 - loss: 0.5324 - val_accuracy: 0.5746 - val_loss: 0.6889\nEpoch 34/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6916 - loss: 0.5294 - val_accuracy: 0.5719 - val_loss: 0.6805\nEpoch 35/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6926 - loss: 0.5299 - val_accuracy: 0.5756 - val_loss: 0.6814\nEpoch 36/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6945 - loss: 0.5269 - val_accuracy: 0.5677 - val_loss: 0.6980\nEpoch 37/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6950 - loss: 0.5256 - val_accuracy: 0.5796 - val_loss: 0.6761\nEpoch 38/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6973 - loss: 0.5236 - val_accuracy: 0.5744 - val_loss: 0.6807\nEpoch 39/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6950 - loss: 0.5232 - val_accuracy: 0.5825 - val_loss: 0.6779\nEpoch 40/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6989 - loss: 0.5213 - val_accuracy: 0.5628 - val_loss: 0.6961\nEpoch 41/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6970 - loss: 0.5201 - val_accuracy: 0.5723 - val_loss: 0.6845\nEpoch 42/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6984 - loss: 0.5176 - val_accuracy: 0.5433 - val_loss: 0.6798\nEpoch 43/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.6987 - loss: 0.5169 - val_accuracy: 0.5782 - val_loss: 0.6961\nEpoch 44/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7017 - loss: 0.5146 - val_accuracy: 0.5774 - val_loss: 0.6851\nEpoch 45/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.6997 - loss: 0.5159 - val_accuracy: 0.5734 - val_loss: 0.6844\nEpoch 46/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7002 - loss: 0.5139 - val_accuracy: 0.5870 - val_loss: 0.6766\nEpoch 47/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7034 - loss: 0.5103 - val_accuracy: 0.5864 - val_loss: 0.6821\nEpoch 48/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7035 - loss: 0.5100 - val_accuracy: 0.5714 - val_loss: 0.6828\nEpoch 49/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7052 - loss: 0.5080 - val_accuracy: 0.5878 - val_loss: 0.6726\nEpoch 50/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7012 - loss: 0.5113 - val_accuracy: 0.5841 - val_loss: 0.6769\nEpoch 51/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7087 - loss: 0.5063 - val_accuracy: 0.5863 - val_loss: 0.6737\nEpoch 52/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7054 - loss: 0.5090 - val_accuracy: 0.5835 - val_loss: 0.6728\nEpoch 53/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7060 - loss: 0.5059 - val_accuracy: 0.5793 - val_loss: 0.6776\nEpoch 54/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7111 - loss: 0.5006 - val_accuracy: 0.5707 - val_loss: 0.6813\nEpoch 55/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7079 - loss: 0.5031 - val_accuracy: 0.5881 - val_loss: 0.6717\nEpoch 56/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7086 - loss: 0.5022 - val_accuracy: 0.5713 - val_loss: 0.6936\nEpoch 57/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7102 - loss: 0.4981 - val_accuracy: 0.5828 - val_loss: 0.6993\nEpoch 58/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7107 - loss: 0.5002 - val_accuracy: 0.5838 - val_loss: 0.6771\nEpoch 59/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7125 - loss: 0.4952 - val_accuracy: 0.5830 - val_loss: 0.6735\nEpoch 60/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7146 - loss: 0.4939 - val_accuracy: 0.5632 - val_loss: 0.6826\nEpoch 61/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7111 - loss: 0.4963 - val_accuracy: 0.5707 - val_loss: 0.6872\nEpoch 62/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7131 - loss: 0.4941 - val_accuracy: 0.5709 - val_loss: 0.6860\nEpoch 63/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7164 - loss: 0.4908 - val_accuracy: 0.5851 - val_loss: 0.6886\nEpoch 64/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7174 - loss: 0.4895 - val_accuracy: 0.5756 - val_loss: 0.6760\nEpoch 65/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7159 - loss: 0.4904 - val_accuracy: 0.5665 - val_loss: 0.6952\nEpoch 66/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7166 - loss: 0.4905 - val_accuracy: 0.5818 - val_loss: 0.6748\nEpoch 67/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7170 - loss: 0.4894 - val_accuracy: 0.5788 - val_loss: 0.6807\nEpoch 68/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7163 - loss: 0.4883 - val_accuracy: 0.5802 - val_loss: 0.6809\nEpoch 69/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7145 - loss: 0.4880 - val_accuracy: 0.5739 - val_loss: 0.6969\nEpoch 70/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7200 - loss: 0.4863 - val_accuracy: 0.5674 - val_loss: 0.7151\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5664 - loss: 0.7198\nFold 4 Test Score:  [0.7150596380233765, 0.5673752427101135]\nFold 4 F1 Score:  0.7049055044924094\nTraining fold 5\nEpoch 1/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.5506 - loss: 0.6898 - val_accuracy: 0.5759 - val_loss: 0.6774\nEpoch 2/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.5800 - loss: 0.6725 - val_accuracy: 0.5698 - val_loss: 0.6798\nEpoch 3/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.5960 - loss: 0.6585 - val_accuracy: 0.5823 - val_loss: 0.6702\nEpoch 4/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6072 - loss: 0.6471 - val_accuracy: 0.5704 - val_loss: 0.6815\nEpoch 5/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6105 - loss: 0.6389 - val_accuracy: 0.5763 - val_loss: 0.6703\nEpoch 6/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6221 - loss: 0.6271 - val_accuracy: 0.5836 - val_loss: 0.6762\nEpoch 7/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6277 - loss: 0.6203 - val_accuracy: 0.5897 - val_loss: 0.6644\nEpoch 8/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6366 - loss: 0.6111 - val_accuracy: 0.6111 - val_loss: 0.6454\nEpoch 9/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6457 - loss: 0.6015 - val_accuracy: 0.5849 - val_loss: 0.6749\nEpoch 10/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6499 - loss: 0.5949 - val_accuracy: 0.6000 - val_loss: 0.6587\nEpoch 11/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6569 - loss: 0.5865 - val_accuracy: 0.6144 - val_loss: 0.6417\nEpoch 12/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6561 - loss: 0.5827 - val_accuracy: 0.6115 - val_loss: 0.6435\nEpoch 13/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6592 - loss: 0.5783 - val_accuracy: 0.6123 - val_loss: 0.6472\nEpoch 14/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6611 - loss: 0.5731 - val_accuracy: 0.6261 - val_loss: 0.6257\nEpoch 15/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6674 - loss: 0.5645 - val_accuracy: 0.6350 - val_loss: 0.6237\nEpoch 16/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6715 - loss: 0.5610 - val_accuracy: 0.6276 - val_loss: 0.6288\nEpoch 17/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6731 - loss: 0.5555 - val_accuracy: 0.6357 - val_loss: 0.6136\nEpoch 18/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6766 - loss: 0.5522 - val_accuracy: 0.6302 - val_loss: 0.6305\nEpoch 19/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6808 - loss: 0.5464 - val_accuracy: 0.6463 - val_loss: 0.6032\nEpoch 20/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6830 - loss: 0.5422 - val_accuracy: 0.6391 - val_loss: 0.6225\nEpoch 21/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6870 - loss: 0.5390 - val_accuracy: 0.6420 - val_loss: 0.6092\nEpoch 22/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6844 - loss: 0.5368 - val_accuracy: 0.6599 - val_loss: 0.5844\nEpoch 23/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6880 - loss: 0.5323 - val_accuracy: 0.6488 - val_loss: 0.6041\nEpoch 24/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6909 - loss: 0.5284 - val_accuracy: 0.6635 - val_loss: 0.5797\nEpoch 25/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6918 - loss: 0.5261 - val_accuracy: 0.6592 - val_loss: 0.5874\nEpoch 26/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6946 - loss: 0.5240 - val_accuracy: 0.6508 - val_loss: 0.6125\nEpoch 27/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6956 - loss: 0.5207 - val_accuracy: 0.6584 - val_loss: 0.5965\nEpoch 28/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6987 - loss: 0.5153 - val_accuracy: 0.6665 - val_loss: 0.5714\nEpoch 29/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6985 - loss: 0.5161 - val_accuracy: 0.6638 - val_loss: 0.5827\nEpoch 30/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.6992 - loss: 0.5119 - val_accuracy: 0.6647 - val_loss: 0.5842\nEpoch 31/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7012 - loss: 0.5097 - val_accuracy: 0.6674 - val_loss: 0.5711\nEpoch 32/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7031 - loss: 0.5068 - val_accuracy: 0.6747 - val_loss: 0.5667\nEpoch 33/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7060 - loss: 0.5041 - val_accuracy: 0.6737 - val_loss: 0.5656\nEpoch 34/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7044 - loss: 0.5027 - val_accuracy: 0.6708 - val_loss: 0.5704\nEpoch 35/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7077 - loss: 0.4993 - val_accuracy: 0.6780 - val_loss: 0.5627\nEpoch 36/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7079 - loss: 0.4963 - val_accuracy: 0.6662 - val_loss: 0.5825\nEpoch 37/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7102 - loss: 0.4977 - val_accuracy: 0.6742 - val_loss: 0.5927\nEpoch 38/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7100 - loss: 0.4967 - val_accuracy: 0.6770 - val_loss: 0.5610\nEpoch 39/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7119 - loss: 0.4927 - val_accuracy: 0.6802 - val_loss: 0.5639\nEpoch 40/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7116 - loss: 0.4917 - val_accuracy: 0.6756 - val_loss: 0.5822\nEpoch 41/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7147 - loss: 0.4888 - val_accuracy: 0.6754 - val_loss: 0.5686\nEpoch 42/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7171 - loss: 0.4866 - val_accuracy: 0.6799 - val_loss: 0.5591\nEpoch 43/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7176 - loss: 0.4850 - val_accuracy: 0.6830 - val_loss: 0.5540\nEpoch 44/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7183 - loss: 0.4810 - val_accuracy: 0.6840 - val_loss: 0.5585\nEpoch 45/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7197 - loss: 0.4802 - val_accuracy: 0.6822 - val_loss: 0.5664\nEpoch 46/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7212 - loss: 0.4787 - val_accuracy: 0.6725 - val_loss: 0.5949\nEpoch 47/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7203 - loss: 0.4796 - val_accuracy: 0.6850 - val_loss: 0.5624\nEpoch 48/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7219 - loss: 0.4777 - val_accuracy: 0.6890 - val_loss: 0.5635\nEpoch 49/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7239 - loss: 0.4716 - val_accuracy: 0.6838 - val_loss: 0.5755\nEpoch 50/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7225 - loss: 0.4755 - val_accuracy: 0.6857 - val_loss: 0.5639\nEpoch 51/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7237 - loss: 0.4722 - val_accuracy: 0.6844 - val_loss: 0.5578\nEpoch 52/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7253 - loss: 0.4702 - val_accuracy: 0.6881 - val_loss: 0.5694\nEpoch 53/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7248 - loss: 0.4703 - val_accuracy: 0.6876 - val_loss: 0.5553\nEpoch 54/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7248 - loss: 0.4698 - val_accuracy: 0.6857 - val_loss: 0.5622\nEpoch 55/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7268 - loss: 0.4690 - val_accuracy: 0.6740 - val_loss: 0.6045\nEpoch 56/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7277 - loss: 0.4703 - val_accuracy: 0.6896 - val_loss: 0.5573\nEpoch 57/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7273 - loss: 0.4662 - val_accuracy: 0.6920 - val_loss: 0.5653\nEpoch 58/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7310 - loss: 0.4622 - val_accuracy: 0.6880 - val_loss: 0.5871\nEpoch 59/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7270 - loss: 0.4662 - val_accuracy: 0.6890 - val_loss: 0.5781\nEpoch 60/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7295 - loss: 0.4630 - val_accuracy: 0.6909 - val_loss: 0.5642\nEpoch 61/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7310 - loss: 0.4604 - val_accuracy: 0.6880 - val_loss: 0.5767\nEpoch 62/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.7324 - loss: 0.4572 - val_accuracy: 0.6906 - val_loss: 0.5747\nEpoch 63/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7311 - loss: 0.4598 - val_accuracy: 0.6956 - val_loss: 0.5875\nEpoch 64/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7324 - loss: 0.4569 - val_accuracy: 0.6959 - val_loss: 0.5639\nEpoch 65/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7334 - loss: 0.4583 - val_accuracy: 0.6804 - val_loss: 0.5911\nEpoch 66/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7315 - loss: 0.4571 - val_accuracy: 0.6922 - val_loss: 0.5607\nEpoch 67/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7335 - loss: 0.4569 - val_accuracy: 0.6944 - val_loss: 0.5550\nEpoch 68/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7377 - loss: 0.4504 - val_accuracy: 0.6923 - val_loss: 0.5840\nEpoch 69/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.7344 - loss: 0.4542 - val_accuracy: 0.6947 - val_loss: 0.5953\nEpoch 70/70\n\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.7350 - loss: 0.4536 - val_accuracy: 0.6945 - val_loss: 0.5783\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6780 - loss: 0.6393\nFold 5 Test Score:  [0.5782657265663147, 0.6945251822471619]\nFold 5 F1 Score:  0.761760816172303\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}